{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HpDiniz/Leitor-de-PDF/blob/main/PDF_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "IojYvkyXF5dg",
        "outputId": "77f5a35a-2d07-4f84-ec7c-dcf91c454c1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4fff2a16-0ded-4658-9cfa-ace3dc647f67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4fff2a16-0ded-4658-9cfa-ace3dc647f67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving - Posicao Consolidada XP - 55432.pdf to - Posicao Consolidada XP - 55432.pdf\n",
            "Saving Brad FIC FI RF Infl Curta.pdf to Brad FIC FI RF Infl Curta.pdf\n",
            "Saving Brad Invest Facil.pdf to Brad Invest Facil.pdf\n",
            "Saving BRADESCO PRIVATE BANK - Relatório de Investimentos Mensal (senha 0745).pdf to BRADESCO PRIVATE BANK - Relatório de Investimentos Mensal (senha 0745).pdf\n",
            "Saving bradesco sem senha.pdf to bradesco sem senha.pdf\n",
            "Saving BTG PACTUAL - Posição de Cotistas.pdf to BTG PACTUAL - Posição de Cotistas.pdf\n",
            "Saving Carteira Itau - Veronica.pdf to Carteira Itau - Veronica.pdf\n",
            "Saving Extrato BB - Cliente 03.pdf to Extrato BB - Cliente 03.pdf\n",
            "Saving Extrato BB 2 - Cliente 03.pdf to Extrato BB 2 - Cliente 03.pdf\n",
            "Saving Extrato Icatu - Cliente 03.pdf to Extrato Icatu - Cliente 03.pdf\n",
            "Saving Extrato Icatu 2 - Cliente 03.pdf to Extrato Icatu 2 - Cliente 03.pdf\n",
            "Saving Extrato Itau - Cliente 02.pdf to Extrato Itau - Cliente 02.pdf\n",
            "Saving Extrato Itau - Cliente 06.pdf to Extrato Itau - Cliente 06.pdf\n",
            "Saving Extrato XP - Cliente 01.pdf to Extrato XP - Cliente 01.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "file_objects = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DRb66puF3wV"
      },
      "source": [
        "# Instalar dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOpgNM0_FHpO"
      },
      "outputs": [],
      "source": [
        "!pip install regex --quiet\n",
        "!pip install PyPDF2 --quiet\n",
        "!pip install pdfminer --quiet\n",
        "!pip install azure.functions --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryWFsxfom0zM",
        "outputId": "bdfea907-6312-4671-d819-2d2507c4fc72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.9/dist-packages (3.4.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-vision) (2.11.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-vision) (3.19.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-vision) (1.22.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.25.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.58.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.16.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.51.3)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.48.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.2.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (2022.12.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-cloud-vision) (0.4.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install google-cloud-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24gX_snRggxl",
        "outputId": "24a1eeee-4387-4701-a87a-18e072ca11a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 174 kB of archives.\n",
            "After this operation, 754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Fetched 174 kB in 1s (259 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 128276 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 4,850 kB of archives.\n",
            "After this operation, 16.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n",
            "Fetched 4,850 kB in 1s (4,292 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 128306 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2build2) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 3,343 kB of archives.\n",
            "After this operation, 15.7 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libarchive-dev amd64 3.4.0-2ubuntu1.2 [491 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libleptonica-dev amd64 1.79.0-1 [1,389 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 libtesseract-dev amd64 4.1.1-2build2 [1,463 kB]\n",
            "Fetched 3,343 kB in 0s (7,547 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 128353 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.4.0-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Selecting previously unselected package libleptonica-dev:amd64.\n",
            "Preparing to unpack .../libleptonica-dev_1.79.0-1_amd64.deb ...\n",
            "Unpacking libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2build2_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Setting up libleptonica-dev:amd64 (1.79.0-1) ...\n",
            "Setting up libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2build2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-por\n",
            "0 upgraded, 1 newly installed, 0 to remove and 23 not upgraded.\n",
            "Need to get 856 kB of archives.\n",
            "After this operation, 1,998 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-por all 1:4.00~git30-7274cfa-1 [856 kB]\n",
            "Fetched 856 kB in 1s (967 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-por.\n",
            "(Reading database ... 128484 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-por_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
            "Unpacking tesseract-ocr-por (1:4.00~git30-7274cfa-1) ...\n",
            "Setting up tesseract-ocr-por (1:4.00~git30-7274cfa-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyMuPDF==1.18.14\n",
            "  Downloading PyMuPDF-1.18.14-cp39-cp39-manylinux2010_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.14\n"
          ]
        }
      ],
      "source": [
        "!apt install tesseract-ocr --quiet\n",
        "!apt install libtesseract-dev --quiet\n",
        "!apt-get install poppler-utils --quiet\n",
        "!apt-get install -y tesseract-ocr-por --quiet\n",
        "\n",
        "!pip install PyMuPDF==1.18.14\n",
        "!pip install pdf2image\n",
        "!pip install pytesseract\n",
        "\n",
        "import fitz\n",
        "import pytesseract\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ2lG9wYwko9",
        "outputId": "a869f15a-2500-40aa-c385-b8f0f523094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.9/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from pdf2image) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q4BAk9TxZ38",
        "outputId": "1105bf46-deb6-436a-a756-f044d6231291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.9/dist-packages (0.3.10)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (8.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5KuaZ64LnZK"
      },
      "source": [
        "# Gerar consolidado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbg7ssU6LpL8"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import uuid\n",
        "import json\n",
        "import time\n",
        "import regex\n",
        "import base64\n",
        "import PyPDF2\n",
        "import openpyxl\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import azure.functions as func\n",
        "import openpyxl.styles as styles\n",
        "\n",
        "from enum import Enum\n",
        "from datetime import datetime\n",
        "from flask import Flask, request\n",
        "from openpyxl.styles import numbers\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NMu-zYLqpg"
      },
      "outputs": [],
      "source": [
        "# REMOVE_SPACES irá retirar espaços indevidos do nome do ativo\n",
        "# REMOVE_FROM_LEFT irá retirar caracteres indevidos à esquerda do nome do ativo\n",
        "# REMOVE_FROM_RIGHT irá retirar caracteres indevidos à direita do nome do ativo\n",
        "class Config(Enum):\n",
        "    REMOVE_SPACES = 1\n",
        "    REMOVE_FROM_LEFT = 2\n",
        "    REMOVE_FROM_RIGHT = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP2oeIGCLqrr"
      },
      "outputs": [],
      "source": [
        "# Define as variáveis globais que serão utilizadas\n",
        "classes_ativos, tickers_list = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZbI1W0uLqtv"
      },
      "outputs": [],
      "source": [
        "def is_valid_request(response, request_data, properties):\n",
        "\n",
        "    # Verifica se o Json possui atributo \n",
        "    for prop in properties:\n",
        "        if prop not in request_data:\n",
        "            response['Status'] = 'FATAL_ERROR'\n",
        "            response['Message'] = 'Propriedade \"' + prop + '\" não informada'\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def get_token(environment):\n",
        "\n",
        "    token = ''\n",
        "    url = \"https://login.microsoftonline.com/a2c97900-6d3e-43a7-9406-645b543c5389/oauth2/v2.0/token\"\n",
        "\n",
        "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        "\n",
        "    data = {\n",
        "        \"grant_type\": \"client_credentials\",\n",
        "        \"client_secret\": \"BWq8Q~A0GFAt4QXR5dKtr6qKMwg1Vacwu2-s5c4U\",\n",
        "        \"client_id\": \"07dccc48-3d83-4cc5-8085-44574e50f16d\",\n",
        "        \"scope\": \"https://org9a1867bf.crm2.dynamics.com/.default\"\n",
        "    }\n",
        "\n",
        "    if environment == 'Prod':\n",
        "        data[\"client_secret\"] = \"2DH8Q~_LI8din2eqL1GADrCGFoMILRBS6lGXJcPg\"\n",
        "        data[\"client_id\"] = \"07dccc48-3d83-4cc5-8085-44574e50f16d\"\n",
        "        data[\"scope\"] = \"https://org5b3d4f09.crm2.dynamics.com/.default\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, data=data)\n",
        "        token = json.loads(response.text)['access_token']\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return token\n",
        "\n",
        "def get_dex_rules(environment):\n",
        "\n",
        "    headers = {\n",
        "        'Authorization': 'Bearer ' + get_token(environment),\n",
        "        'Content-Type': 'application/x-www-form-urlencoded',\n",
        "        'Prefer': 'odata.include-annotations=\"OData.Community.Display.V1.FormattedValue\"'\n",
        "    }\n",
        "\n",
        "    base_url = \"https://org9a1867bf.crm2.dynamics.com\"\n",
        "\n",
        "    if environment == 'Prod':\n",
        "        base_url = \"https://org5b3d4f09.crm2.dynamics.com\"\n",
        "\n",
        "    # Obtém todas as classes e tipos de ativos\n",
        "    try:\n",
        "        response = requests.get(base_url + \"/api/data/v9.2/cr11f_dex_rules\", headers=headers)\n",
        "        json_content = json.loads(response.text)\n",
        "\n",
        "        for val in json_content['value']:\n",
        "            classes_ativos.append({\n",
        "                \"Classe do Ativo\": val['cr11f_classedoativo@OData.Community.Display.V1.FormattedValue'],\n",
        "                \"Tipo do Ativo\": val['cr11f_tipodoativo@OData.Community.Display.V1.FormattedValue'],\n",
        "                \"Termo Buscado\": val['cr11f_termobuscado'],\n",
        "                \"Busca Exata\": val['elogroup_buscaexata'],\n",
        "                \"Regra Prioritária\": bool(val['cr11f_regraprioritaria'])\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    # Obtém todos os tickers de Fundos Imobiliários\n",
        "    try:\n",
        "        response = requests.get(base_url + \"/api/data/v9.2/elogroup_dex_realstatefunds\", headers=headers)\n",
        "        json_content = json.loads(response.text)\n",
        "\n",
        "        for jss in json_content['value']:\n",
        "            tickers_list.append(jss['elogroup_ticker'])\n",
        "    except Exception as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbRd3sxCLqv1"
      },
      "outputs": [],
      "source": [
        "def pdf_requires_password(file_name):\n",
        "\n",
        "    # Abra o arquivo PDF\n",
        "    with open(file_name, mode='rb') as file:\n",
        "        # Leia o arquivo PDF\n",
        "        pdf_reader = PyPDF2.PdfReader(file_name)\n",
        "\n",
        "        return pdf_reader.is_encrypted\n",
        "\n",
        "def mes_para_numero(data):\n",
        "\n",
        "    mes, ano = data.split()\n",
        "\n",
        "    meses = {\n",
        "        \"janeiro\": \"31/01/\" + str(ano),\n",
        "        \"fevereiro\": \"28/02/\" + str(ano),\n",
        "        \"março\": \"31/03/\" + str(ano),\n",
        "        \"abril\": \"30/04/\" + str(ano),\n",
        "        \"maio\": \"31/05/\" + str(ano),\n",
        "        \"junho\": \"30/06/\" + str(ano),\n",
        "        \"julho\": \"31/07/\" + str(ano),\n",
        "        \"agosto\": \"31/08/\" + str(ano),\n",
        "        \"setembro\": \"30/09/\" + str(ano),\n",
        "        \"outubro\": \"31/10/\" + str(ano),\n",
        "        \"novembro\": \"30/11/\" + str(ano),\n",
        "        \"dezembro\": \"31/12/\" + str(ano)\n",
        "    }\n",
        "    return meses.get(mes.lower().strip(), None)\n",
        "\n",
        "# Converte o conteúdo do PDF para texto\n",
        "def get_pdfminer_text(path):\n",
        "\n",
        "    retstr = io.StringIO()\n",
        "    laparams = LAParams()\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "\n",
        "    fp = open(path, 'rb')\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "\n",
        "    for page in PDFPage.get_pages(fp, set(), maxpages=0, password=\"\",caching=True, check_extractable=True):\n",
        "        interpreter.process_page(page)\n",
        "\n",
        "    text = retstr.getvalue()\n",
        "\n",
        "    fp.close()\n",
        "    device.close()\n",
        "    retstr.close()\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def get_pypdf_text(path):\n",
        "\n",
        "    text = \"\"\n",
        "\n",
        "    try:\n",
        "        reader = PyPDF2.PdfReader(path)\n",
        "        for page in reader.pages:\n",
        "            text = text + page.extract_text()\n",
        "    except:\n",
        "        print(\"Falha ao ler pdf com pypdf\")\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def get_images_text(path):\n",
        "\n",
        "    # Armazena o texo extraído\n",
        "    text = \"\"\n",
        "\n",
        "    try:\n",
        "        # Define os parâmetros de renderização da imagem\n",
        "        images = [] # lista para armazenar as imagens obtidas\n",
        "        zoom_x = 2.5 # resolução horizontal em pontos por polegada (DPI)\n",
        "        zoom_y = 2.5 # resolução vertical em pontos por polegada (DPI)\n",
        "        mat = fitz.Matrix(zoom_x, zoom_y)  # matriz de transformação\n",
        "        anti_aliasing = True  # ativa o anti-aliasing\n",
        "\n",
        "        # Abre o arquivo PDF\n",
        "        with fitz.open(path) as doc:\n",
        "            # Percorre todas as páginas do PDF\n",
        "            for i in range(doc.page_count):\n",
        "                # Seleciona a página atual\n",
        "                page = doc[i]\n",
        "                # Renderiza a página como imagem\n",
        "                pix = page.getPixmap(matrix=mat, alpha=anti_aliasing)\n",
        "                # Gera um nome de arquivo aleatório\n",
        "                filename = '/tmp/' + str(uuid.uuid4()) + '.png'\n",
        "                # Salva a imagem como um arquivo PNG\n",
        "                pix.writePNG(filename)\n",
        "                # Adiciona a imagem à um array de imagens\n",
        "                images.append(Image.open(filename))\n",
        "                \n",
        "        # Define o tamanho e a largura da imagem resultante\n",
        "        widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "        # Calcula a largura e altura totais da imagem resultante\n",
        "        total_width = max(widths)\n",
        "        total_height = sum(heights)\n",
        "\n",
        "        # Cria uma nova imagem do tamanho necessário\n",
        "        merged_image = Image.new('RGB', (total_width, total_height))\n",
        "\n",
        "        # Define a posição inicial para colar a próxima imagem\n",
        "        y_offset = 0\n",
        "\n",
        "        # Salva cada imagem em um arquivo PNG\n",
        "        for i, image in enumerate(images):\n",
        "            merged_image.paste(image, (0, y_offset))\n",
        "            y_offset += image.size[1]\n",
        "        \n",
        "        # Gera um nome de arquivo aleatório\n",
        "        filename = '/tmp/' + str(uuid.uuid4()) + '.png'\n",
        "\n",
        "        # Salva a imagem mesclada em um arquivo\n",
        "        merged_image.save(filename)\n",
        "\n",
        "        # Extrai o texto da imagem mesclada com a configuração '--psm 6'\n",
        "        text = pytesseract.image_to_string(Image.open(filename), lang='por')\n",
        "\n",
        "        # Remove a imagem\n",
        "        os.remove(filename)\n",
        "    except:\n",
        "        print(\"Falha ao ler pdf com OCR\")\n",
        "\n",
        "    return text\n",
        "\n",
        "def obtem_linhas_formatadas(text, split_condition):\n",
        "\n",
        "    pdfminer_lines = text.split(split_condition)\n",
        "\n",
        "    # Remove tabs, quebras de linhas e espaços duplos de cada posição\n",
        "    for i in range(len(pdfminer_lines)):\n",
        "        pdfminer_lines[i] = regex.sub('\\s+',' ', pdfminer_lines[i].strip())\n",
        "        \n",
        "    return sorted(pdfminer_lines, key=lambda s: len(s), reverse=True)\n",
        "\n",
        "def check_ativo_noise(noise_config, ativo):\n",
        "\n",
        "    if not 'text' in noise_config and not 'config' in noise_config:\n",
        "        return ativo.strip()\n",
        "\n",
        "    text, config = noise_config['text'], noise_config['config']\n",
        "\n",
        "    # Remove espaços extras do ativo\n",
        "    ativo = regex.sub('\\s+',' ', ativo.strip())\n",
        "\n",
        "    # Obtém todas as linhas formatadas\n",
        "    pdfminer_lines = obtem_linhas_formatadas(text,'\\n\\n')\n",
        "\n",
        "    if config == Config.REMOVE_SPACES:\n",
        "\n",
        "        # Percorre todas as linhas obtidas pelo pdfminer\n",
        "        for line in pdfminer_lines:\n",
        "\n",
        "            # Se o ativo for encontrado no pdfminer, retorna o nome correto do ativo\n",
        "            if regex.sub('\\s+','', line) in regex.sub('\\s+','', ativo):\n",
        "                if line != '':\n",
        "                    return line.strip()\n",
        "\n",
        "    elif config == Config.REMOVE_FROM_LEFT or config == Config.REMOVE_FROM_RIGHT:\n",
        "\n",
        "        # Cria uma cópia do nome do ativo\n",
        "        ativo_aux = ativo\n",
        "\n",
        "        #Loop até quando for possível diminuir o nome do ativo\n",
        "        while(len(ativo_aux) > 1):\n",
        "\n",
        "            # Se o nome do ativo não possuir espaços, não há o que fazer\n",
        "            if ' ' not in ativo_aux:\n",
        "                return ativo.strip()\n",
        "\n",
        "            # Procura o nome do ativo nas linhas do pdfminer\n",
        "            if ativo_aux in pdfminer_lines:\n",
        "                return ativo_aux.strip()\n",
        "\n",
        "            # Remove um caracter do {ativo_aux} e conitnua a busca\n",
        "            if config == Config.REMOVE_FROM_LEFT:\n",
        "                ativo_aux = ativo_aux[1:]\n",
        "            else:\n",
        "                ativo_aux = ativo_aux[:-1]\n",
        "    \n",
        "    # Retorna o {ativo}, caso não tenha sido encontrado nada\n",
        "    return ativo.strip()\n",
        "\n",
        "def convert_base64_to_file(file_encoded, extension):\n",
        "\n",
        "    bytes = base64.b64decode(file_encoded, validate=True)\n",
        "\n",
        "    temp_file = '/tmp/' + str(uuid.uuid4()) + '.' + extension\n",
        "\n",
        "    # Write the PDF contents to a local file\n",
        "    f = open(temp_file, 'wb')\n",
        "    f.write(bytes)\n",
        "    f.close()\n",
        "\n",
        "    return temp_file\n",
        "\n",
        "def read_pdf_file_content(temp_file):\n",
        "\n",
        "    # Lê o conteúdo do arquivo PDF\n",
        "    text_pypdf = get_pypdf_text(temp_file)\n",
        "    text_pdfminer = get_pdfminer_text(temp_file)\n",
        "    text_images = \"\" if (len(text_pdfminer) + len(text_pypdf) > 200) else get_images_text(temp_file)\n",
        "\n",
        "    # Deleta o arquivo temporário\n",
        "    os.remove(temp_file)\n",
        "\n",
        "    return text_pypdf, text_pdfminer, text_images\n",
        "\n",
        "def limpar_caracteres(text):\n",
        "    # Retira todos os caracteres ilegais ou em excesso\n",
        "    return regex.sub('[\\s\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F-\\x9F]+',' ', text.strip())\n",
        "\n",
        "def json_to_excel(json):\n",
        "\n",
        "    print(\"Generating Excel file...\")\n",
        "\n",
        "    # Converte o Json para DataFrame\n",
        "    df = pd.DataFrame(json)\n",
        "    df.astype({'ATUAL': 'float'}).dtypes\n",
        "\n",
        "    # Gera um nome de arquivo aleatório\n",
        "    filename = '/tmp/' + str(uuid.uuid4()) + '.xlsx'\n",
        "\n",
        "    # Criar o arquivo Excel\n",
        "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
        "    \n",
        "    df.to_excel(writer, index=False, float_format=\"%.2f\")\n",
        "\n",
        "    workbook = writer.book\n",
        "    worksheet = writer.sheets['Sheet1']\n",
        "\n",
        "    # percorrer todas as células do Worksheet\n",
        "    for row in worksheet.iter_rows():\n",
        "        for cell in row:\n",
        "            # verificar se o valor da célula corresponde à regex \\d{2}\\/\\d{2}\\/\\d{4}\n",
        "            if cell.value and regex.match(r'^\\d{2}\\/\\d{2}\\/\\d{4}$', str(cell.value)):\n",
        "                # definir a propriedade 'number_format' como 'dd/mm/yyyy'\n",
        "                cell.number_format = 'dd/mm/yyyy'\n",
        "                # converter a string para um objeto Timestamp antes de fazer a subtração\n",
        "                cell.value = pd.to_datetime(cell.value, format='%d/%m/%Y')\n",
        "\n",
        "    for i, col in enumerate(df.columns):\n",
        "        column_len = df[col].astype(str).str.len().max()\n",
        "        column_len = max(column_len, len(col)) + 2\n",
        "        worksheet.column_dimensions[openpyxl.utils.get_column_letter(i+1)].width = column_len\n",
        "\n",
        "        for j, cell in enumerate(worksheet['{}:{}'.format(openpyxl.utils.get_column_letter(i+1), openpyxl.utils.get_column_letter(i+1))]):\n",
        "            if j != 0 and col == \"IMAGEM\" and cell.value == \"SIM\":\n",
        "                # Definir estilo para colorir as células de laranja\n",
        "                for k in range(len(df.columns)):\n",
        "                    worksheet.cell(row=j+1, column=k+1).fill = styles.PatternFill(start_color='FCD5B4', end_color='FCD5B4', fill_type='solid')\n",
        "                    \n",
        "            if df[col].dtype == 'float64':\n",
        "                worksheet.cell(row=j+1, column=i+1).number_format = numbers.FORMAT_NUMBER_COMMA_SEPARATED1\n",
        "\n",
        "    # Remove a coluna auxiliar que diz se foi feita extração via OCR\n",
        "    worksheet.delete_cols(df.columns.get_loc('IMAGEM')+1)\n",
        "\n",
        "    # Salvar o arquivo Excel\n",
        "    writer.close()\n",
        "\n",
        "    with open(filename, \"rb\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    os.remove(filename)\n",
        "\n",
        "    return base64.b64encode(content).decode(\"utf-8\")\n",
        "\n",
        "def update_file_status(response, file_name, extraction_result):\n",
        "\n",
        "    if 'FileStatus' not in response:\n",
        "        response['FileStatus'] = []\n",
        "\n",
        "    response['FileStatus'].append({\n",
        "        'FileName': file_name,\n",
        "        'Status': extraction_result['Status'],\n",
        "        'Message': extraction_result['Message']\n",
        "    })\n",
        "\n",
        "def normalizar_texto_ocr(text):\n",
        "\n",
        "    # Corrige caracteres que possuem grande potencial de serem um zero\n",
        "    new_text = regex.sub(r\"(?<=(\\d|(o|O|º))\\s)(o|O|º)(?=\\s(\\d|(o|O|º)\\s|R\\$))\", \"0\", text)\n",
        "\n",
        "    # Remove caracteres especiais colocados de maneira incorreta entre os dados da tabela\n",
        "    new_text = regex.sub(r\"((?<=\\d\\s*)([^\\w% ])(?=\\s+(\\d|R\\$))|(?<=\\d\\s+)([^\\w% ])(?=\\s*(\\d|R\\$)))\", \"\", new_text)\n",
        "\n",
        "    # Garante que todo valor monetário possuirá uma vírgula seguido de dois números\n",
        "    tuple_array = regex.finditer(r'R\\$[\\d.]+(?=\\s)', new_text) \n",
        "    for r in tuple_array:\n",
        "        item = r.group(0)\n",
        "        x = regex.sub(r'(?<=R\\$[\\d\\.]*\\d)(?=\\d\\d(\\D|$))', ',', item)\n",
        "        new_text = new_text.replace(item, x)\n",
        "\n",
        "    return new_text, new_text\n",
        "\n",
        "def busca_termos(ativo, classes_interesse):\n",
        "\n",
        "    # Variáveis para armazenar os resultados obtidos\n",
        "    classes = set()\n",
        "    tipos = set()\n",
        "\n",
        "    for tipo in classes_interesse:\n",
        "        \n",
        "        pattern = r'' + tipo['Termo Buscado'] + r''\n",
        "\n",
        "        if(tipo['Busca Exata']):\n",
        "            pattern = r'\\b' + tipo['Termo Buscado'] + r'\\b'        \n",
        "\n",
        "        possui_aspas = regex.search(r'(?<=\\\").*(?=\\\")', tipo['Termo Buscado'], flags=(regex.IGNORECASE))\n",
        "\n",
        "        if possui_aspas:\n",
        "            pattern = r'\\b' + possui_aspas.group(0).replace(\"x\",\"[A-Z]\").replace(\"n\",\"\\d\") + r'\\b'\n",
        "\n",
        "        if regex.search(pattern, ativo, flags=(regex.IGNORECASE)):\n",
        "            classes.add(tipo['Classe do Ativo'])\n",
        "            tipos.add(tipo['Tipo do Ativo'])\n",
        "\n",
        "    if '-' in classes and len(classes) > 1:\n",
        "        classes.remove('-')\n",
        "\n",
        "    if '-' in tipos and len(tipos) > 1:\n",
        "        tipos.remove('-')\n",
        "\n",
        "    return classes, tipos\n",
        "\n",
        "def obtem_classificacao(ativo):\n",
        "\n",
        "    # Separa as classes de ativos em prioritárias e não prioritárias\n",
        "    classes_prioritarias = list(filter(lambda x: x['Regra Prioritária'], classes_ativos)) \n",
        "    classes_normais = list(filter(lambda x: x['Regra Prioritária'] == False, classes_ativos)) \n",
        "\n",
        "    # Primeiramente, verificamos as classes prioritárias\n",
        "    classes, tipos = busca_termos(ativo, classes_prioritarias)\n",
        "\n",
        "    if len(classes) == 0:\n",
        "\n",
        "        # Segundamente, verificamos se o ativo é um FII\n",
        "        potencial_fii = regex.search(r'\\b[A-Z]{4}11\\b', ativo)\n",
        "        if potencial_fii != None and potencial_fii.group(0) in tickers_list:\n",
        "            return \"Renda Fixa\", \"Fundos Imobiliários\"\n",
        "\n",
        "        # Por último, verificamos as classes não prioritárias\n",
        "        classes, tipos = busca_termos(ativo, classes_normais)\n",
        "\n",
        "    classe_result = ' / '.join(classes) if len(classes) > 0 else '***'\n",
        "    tipo_result = ' / '.join(tipos) if len(tipos) > 0 else '***'\n",
        "    \n",
        "    return classe_result, tipo_result\n",
        "\n",
        "def get_first_tuple(result):\n",
        "\n",
        "    # Etapa para padronizar resultados que são um array simples e os que são array de tuplas\n",
        "    if len(result) > 0 and type(result[0]) is tuple:\n",
        "        result = result[0]\n",
        "\n",
        "    return result\n",
        "\n",
        "def apply_regex_at_position(array, target_index, pattern, group_index):\n",
        "\n",
        "    # Para cada elemento do array, aplica uma regex na posição especificada\n",
        "    for i in range(len(array)):\n",
        "        array_list = list(array[i])\n",
        "        group = regex.findall(pattern, array_list[target_index], flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "\n",
        "        # Se nenhum resultado foi obtido, ignora o elemento atual\n",
        "        if len(group) == 0:\n",
        "            continue\n",
        "\n",
        "        # Etapa para padronizar resultados que são um array simples e os que são array de tuplas\n",
        "        group = get_first_tuple(group)\n",
        "\n",
        "        # Verifica se o index informado pode ser acessado\n",
        "        if len(group) > group_index:\n",
        "            array_list[target_index] = group[group_index]\n",
        "            array[i] = array_list\n",
        "\n",
        "def obtem_ativos_ate_100_por_cento(array, percent_index):\n",
        "    \n",
        "    # Inicializa o contador e o novo array\n",
        "    total = 0.0\n",
        "    new_array = []\n",
        "    \n",
        "    # Adiciona todos os items do array ao novo array, até atingir 100.00 ou mais\n",
        "    for item in array:\n",
        "        new_array.append(item)\n",
        "        total = total + float(item[percent_index])\n",
        "        if(total >= 100.0):\n",
        "            return new_array\n",
        "    \n",
        "    return array\n",
        "\n",
        "def gera_ativo_santander(array, ativo_idx, text_pypdf, text_pdfminer, used_indexes = []):\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_SPACES}\n",
        "\n",
        "    result = []\n",
        "    for i in range(len(array)):\n",
        "\n",
        "        tuple_item = list(array[i])\n",
        "\n",
        "        # Obtém o valor dos atributos\n",
        "        ativo = \"\" if ativo_idx is None else regex.sub('\\s+',' ', array[i][ativo_idx].strip())\n",
        "        ativo = check_ativo_noise(noise_config, ativo) if noise_config != {} else ativo\n",
        "\n",
        "        # Constrói a regex que será utilizada para obter o tipo do ativo\n",
        "        pattern = r'(?<='\n",
        "        for i in range(len(tuple_item)):\n",
        "            if i in used_indexes:\n",
        "                pattern = pattern + regex.compile(r'([^\\w\\s])').sub(r'\\\\\\1', tuple_item[i]).replace('\\n','\\s*?') + r'(.*?)'\n",
        "\n",
        "        pattern = pattern + r'.*?\\s*)Total.*?(?=\\d)'\n",
        "\n",
        "        tipo_ativo = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.DOTALL))\n",
        "\n",
        "        tipo_ativo = \"\" if tipo_ativo is None else regex.sub('\\s+',' ', tipo_ativo.group(0).strip())\n",
        "        tipo_ativo = check_ativo_noise(noise_config, tipo_ativo)\n",
        "\n",
        "        retirar_palavras = ['total', 'por']\n",
        "        for palavra in retirar_palavras:\n",
        "            tipo_ativo = regex.sub(r'\\b' + palavra + r'\\b', '', tipo_ativo, flags=(regex.IGNORECASE)).strip()\n",
        "\n",
        "        tuple_item[ativo_idx] = tipo_ativo + \" - \" + ativo if ativo != \"\" else tipo_ativo\n",
        "\n",
        "        result.append(tuple_item)\n",
        "\n",
        "    return result\n",
        "\n",
        "def extract_info(result, array, ativo_idx, valor_idx, vencimento_idx, indexador_idx, data_emissao, file_name, is_image, instituicao, noise_config = None, is_coe = False):\n",
        "\n",
        "    for item in array:\n",
        "\n",
        "        # Obtém o valor dos atributos\n",
        "        ativo = \"\" if ativo_idx is None else limpar_caracteres(item[ativo_idx])\n",
        "        valor_atual = \"-\" if valor_idx is None else limpar_caracteres(item[valor_idx])\n",
        "        data_vencimento = \"-\" if vencimento_idx is None else limpar_caracteres(item[vencimento_idx])\n",
        "        indexador = \"-\" if indexador_idx is None else regex.sub('^\\+\\s*','', limpar_caracteres(item[indexador_idx]))\n",
        "\n",
        "        # Garante que o ativo capturado possua letras\n",
        "        if ativo != '' and not regex.search(r'[a-zA-Z]', ativo):\n",
        "            continue\n",
        "\n",
        "        # Define valor padrão de COE para a classificação e o tipo\n",
        "        classificacao = \"Multimercado\"\n",
        "        tipo_ativo = \"Certificado de Operações Estruturadas\"\n",
        "\n",
        "        # Caso não seja um COE, obtenha a classificação real  \n",
        "        if not is_coe:\n",
        "            classificacao, tipo_ativo = obtem_classificacao(ativo)\n",
        "\n",
        "        # Altera a data de vencimento para o padrão dd/mm/yyyy\n",
        "        if regex.search(r'^\\d{2}\\/\\d{2}\\/\\d{2}$', data_vencimento):\n",
        "            data_vencimento = data_vencimento[0:6] + '20' + data_vencimento[6:8]\n",
        "\n",
        "        # Realiza formatações adicionais\n",
        "        ativo = \"***\" if ativo == '' else (check_ativo_noise(noise_config, ativo) if noise_config != None else ativo)\n",
        "        ativo = \"COE - \" + ativo if is_coe else ativo\n",
        "        data_emissao = limpar_caracteres(data_emissao)\n",
        "        valor_atual = float(valor_atual.replace('.','').replace(',','.')) if regex.search(r'\\d', valor_atual) else None\n",
        "        data_vencimento = data_vencimento if regex.search(r'^\\d{2}\\/\\d{2}\\/\\d{4}$', data_vencimento) else \"-\"\n",
        "\n",
        "        result.append({\n",
        "            'TITULARIDADE': '***',\n",
        "            'CLASSIFICAÇÃO': classificacao,\n",
        "            'NOME DO ATIVO': ativo,\n",
        "            'EXPOSIÇÃO': \"Real\",\n",
        "            'INSTITUIÇÃO': instituicao,\n",
        "            'ATUAL': valor_atual,\n",
        "            'MOEDA DE EXIBIÇÃO': \"Real\",\n",
        "            'DATA': data_emissao,\n",
        "            'ON/OFF': \"ON\",\n",
        "            'DATA DE VENCIMENTO': data_vencimento,\n",
        "            'INDEXADOR': indexador,\n",
        "            '[APOIO] ORIGEM EXTRATO': file_name,\n",
        "            '[APOIO] TIPO DO ATIVO': tipo_ativo,\n",
        "            'IMAGEM': \"SIM\" if is_image else \"NÃO\"\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-xD_APULqx7"
      },
      "outputs": [],
      "source": [
        "def obtem_extrato_cotista_xp(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Regex para obter a data de emissão\n",
        "    pattern = \"(?<=Movimenta..o de \\d{2}\\/\\d{2}\\/\\d{4} a )\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o texto situado entre o termo \"POSIÇÃO CONSOLIDADA\" e o termo \"Emissão\"\n",
        "    pattern = \"(?<=POSI..O CONSOLIDADA).*?(?=Emissão:)\"\n",
        "    result_1 = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem pelo menos uma letra e um espaço\n",
        "    pattern = \"^.*[a-zA-Z] .*$\"\n",
        "    result_2 = regex.finditer(pattern, result_1, flags=(regex.MULTILINE))\n",
        "\n",
        "    # Regex para obter o texto situado entre o termo \"POSIÇÃOCONSOLIDADA\" e o termo \"TotalnaInstituição\"\n",
        "    pattern = \"(?<=POSI..OCONSOLIDADA\\n).*?(?=TotalnaInstituição)\"\n",
        "    result_3 = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Substitui os espaços por um ponto e vírgula, para simular uma tabela CSV\n",
        "    result_3 = result_3.replace(\" \",\";\")\n",
        "\n",
        "    # Corrige termos com espaço\n",
        "    for result in result_2:\n",
        "        value = result.group(0)\n",
        "        key = value.replace(\" \",\"\")\n",
        "        result_3 = result_3.replace(key,value)\n",
        "\n",
        "    # Converte a tabela CSV para um array de valores\n",
        "    df_array = pd.read_csv(io.StringIO(result_3), sep=\";\").to_numpy()\n",
        "    \n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "    extract_info(result, df_array, 0, 4, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_diario_modal(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = \"(?<=posi..o\\s*de\\s*)\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos e seus preços brutos\n",
        "    pattern = r'(^.*?)[\\d]+.*?(CNPJ\\:\\d{2}\\-\\d{3}\\-\\d{3}\\/\\d{4}\\-\\d{2})(.|\\n)*?Total\\s*do\\s*Fundo\\s*[\\d.]+\\,\\d+\\s*[\\d.]+\\,\\d+\\s*([\\d.]+\\,\\d+)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "\n",
        "    # Adiciona o CNPJ ao nome do ativo\n",
        "    tuple_array = [[item[0] + \" (\" + item[1] + \")\", item[3]] for item in tuple_array]\n",
        "    extract_info(result, tuple_array, 0, 1, None, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_consolidado_modal(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define as expressões proibidas que não podem estar no nome do ativo\n",
        "    banned_words = r'((?!(\\,\\d\\d|\\d{2}\\/\\d{2}\\/\\d{4}|bruto|l.quido|dividendo|provento|rendimento|juros\\s*sobre\\s*capital)).)*?'\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = \"(?<=Per.odo de refer.ncia \\d{2}\\/\\d{2}\\/\\d{4} a )\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "    \n",
        "    # Regex para obter RENDA FIXA\n",
        "    pattern = r'(?<=(\\,\\d\\d|L.QUIDO))\\s*([A-Z]' + banned_words + r')\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*R\\$\\s*[\\d,.]+\\,\\d{2}\\s*[\\d\\n.]+\\s*R\\$\\s*([\\d,.]+\\,\\d{2})\\s*R\\$\\s*[\\d,.]+\\,\\d{2}\\s*[\\d\\n.]+\\,\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 1, 5, 4, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "\n",
        "    # Regex para obter BOVESPA / AÇÕES, FIIS E ETFS\n",
        "    pattern = r'(?<=(\\,\\d\\d|BRUTO))\\s*([A-Z]' + banned_words + r'(34|35|33|32|11|6|5|4|3))\\s*?[\\d.]+?\\s*R\\$\\s*[\\d\\n.]+\\,\\d{2}\\s*R\\$\\s*([\\d\\n.]+\\,\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 1, 5, None, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "\n",
        "    # Regex para obter DEBENTURES\n",
        "    pattern = r'(?<=(\\,\\d\\d|L.QUIDO))\\s*([A-Z]' + banned_words + r')\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*[\\d\\n.]+\\s*R\\$\\s*([\\d\\n.]+\\,\\d{2})\\s*R\\$\\s*[\\d\\n.]+\\,\\d{2}\\s*R\\$\\s*[\\d\\n.]+\\,\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 1, 4, None, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "    \n",
        "    # Regex para obter FUNDOS DE INVESTIMENTOS\n",
        "    pattern = r'(?<=(\\,\\d\\d|L.QUIDO))\\s*\\s*([A-Z]' + banned_words + r')\\s*[\\d\\n.]+?\\,[\\d\\n]+?\\s*R\\$\\s*[\\d\\n.]+?\\,[\\d\\n]+?\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*R\\$\\s*([\\d\\n.]+?\\,[\\d\\n]+?)\\s*R\\$\\s*[\\d\\n.]+?\\,[\\d\\n]+\\s*R\\$\\s*[\\d\\n.]+?\\,\\d\\d'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 1, 4, None, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "\n",
        "    # Regex para obter PREVIDENCIA PRIVADA\n",
        "    pattern = r'(?<=(\\,\\d\\d|L.QUIDO))\\s*\\s*([A-Z]' + banned_words + r')\\s*R\\$\\s*([\\d\\n.]+?\\,[\\d\\n]+?)\\s*R\\$\\s*[\\d\\n.]+?\\,[\\d\\n]+\\s*R\\$\\s*[\\d\\n.]+?\\,\\d\\d'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 1, 4, None, None, data_emissao, file_name, is_image, \"Modal\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "def obtem_posicao_performance_xp(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = \"(?<=Data da consulta: )\\d\\d\\/\\d\\d\\/\\d{4}\"\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "    \n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    pattern = r'(((?!\\d{2}\\/\\d{2}\\/\\d{4}).)*)\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4}|\\-)\\s*(\\d{2}\\/\\d{2}\\/\\d{4})([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s]*)([\\d.]+\\,\\d\\d)[\\d.]+\\,\\d\\d'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 5, 3, 4, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de COE\n",
        "    pattern = r'(((?!\\d{2}\\/\\d{2}\\/\\d{4}).)*)\\d{2}\\/\\d{2}\\/\\d{4}[\\s\\d.]+\\,\\d\\d([\\d.]+\\,\\d\\d)[\\d.]+\\,\\d\\d'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de COE\n",
        "    pattern = r'(((?!\\d{2}\\/\\d{2}\\/\\d{4}).)*)\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*[\\d.]+\\,\\d\\d[\\d.]+\\,\\d\\d([\\d.]+\\,\\d\\d)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))   \n",
        "    extract_info(result, tuple_array, 0, 3, 2, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config, is_coe = True)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Previdência\n",
        "    pattern = r'(((?!\\d{2}\\/\\d{2}\\/\\d{4}).)*)\\d{2}\\/\\d{2}\\/\\d{4}\\s*[\\d.]+\\,\\d{2}\\s*[\\d.]+\\s*([\\d.]+\\,\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))  \n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de ??\n",
        "    pattern = r'([A-Z]{4}(34|35|33|32|11|6|5|4|3))[\\d\\s.]*\\,\\d\\d\\s*[\\d.]+\\,\\d\\d\\s*[\\d\\-\\+]+\\,\\d\\d\\s*([\\d.]+\\,\\d\\d)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))   \n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)    \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_posicao_consolidada_xp(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "\n",
        "    # Se for uma extração de imagem, realiza a normalização do texto\n",
        "    if is_image:\n",
        "        text_pypdf, text_pdfminer = normalizar_texto_ocr(text_pypdf)\n",
        "        noise_config = None\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = \"(?<=Data da Consulta: )\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    pattern = r'\\n[\\d\\/]*([A-Z].+?\\s*-\\s*\\w{3}\\/\\d{4})\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s]*)\\d+\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "\n",
        "    extract_info(result, tuple_array, 0, 3, 1, 2, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)   \n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa sem carência\n",
        "    pattern = r'\\n[\\d\\/]*([A-Z].+?\\s*-\\s*\\w{3}\\/\\d{4})\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*\\-\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s]+)\\d+\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 3, 1, 2, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)  \n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa Pós-Fixados\n",
        "    pattern = r'\\n[\\d\\/]*([A-Z]((?!\\d{2}\\/\\d{2}\\/\\d{4}).)+)\\s*\\d{2}\\/\\d{2}\\/(\\d{4})\\s*[\\d,.]+\\s*[\\d,.]+\\s*R\\$\\s*[\\d,.]+(\\s*)R\\$\\s*([\\d,.]+)\\s*R\\$\\s*[\\d,.]+'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 4, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)  \n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem Fundos Imobiliários\n",
        "    pattern = r'([A-Z]{4}(34|35|33|32|11|6|5|4|3))\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+R\\$\\s*[\\d,.]+[.,]\\d{2}(\\s*)R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 3, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem COEs\n",
        "    pattern = r'\\n[\\d\\/]*([A-Z]((?!\\d{2}\\/\\d{2}\\/\\d{4}).)+)\\s*-\\s*[\\w\\s,.]*\\s*-\\s*\\s*\\d{2}\\.\\d{2}\\.\\d{4}\\s*[\\w\\s,.]*\\d{2}\\/\\d{2}\\/\\d{4}\\s+(\\d{2}\\/\\d{2}\\/\\d{4})\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}(\\s*)R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 4, 2, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config, is_coe = True)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem Ações\n",
        "    pattern = r'([A-Z]{4}(34|35|33|32|11|6|5|4|3))\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+R\\$\\s*[\\d,.]+[.,]\\d{2}(\\s*)R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 3, None, None, data_emissao, file_name, is_image, \"XP Investimentos\", noise_config)\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_posicao_consolidada_genial(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "    \n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Emissão:\\xa0)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    pattern = r'(((?!MULTIMERCADO|RENDA FIXA|PREVIDÊNCIA|AÇÕES).)*).+?\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*R\\$([\\d.]+\\,\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"Genial\", noise_config)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    pattern = r'^([A-Z].*?)\\s*[\\d.]+\\,\\d{2}\\s*[\\d.]+\\,\\d{2}\\s*[\\d.]+\\,\\d{2}\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*R\\$\\s*([\\d.]+\\,\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 2, 1, None, data_emissao, file_name, is_image, \"Genial\", noise_config)\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_carteira_investimentos_itau(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(janeiro|fevereiro|março|abril|maio|junho|julho|agosto|setembro|outubro|novembro|dezembro)\\s\\d{4}'\n",
        "    data_emissao = mes_para_numero(regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0))\n",
        "    \n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'((.*\\n){5})([\\d.]+\\,\\d{2})\\s*([\\- \\d\\%]+|\\d{2}\\/\\d{2}\\/\\d{2})\\s*([\\- \\d\\%]+|\\d{2}\\/\\d{2}\\/\\d{2})\\s*([\\d\\%A-Z\\+\\-\\,\\.]+\\s*[\\d\\%A-Z\\+\\-\\,\\.]*?)\\s*\\d{0,3}\\%\\s*(Alto|Baixo|M.dio)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    apply_regex_at_position(tuple_array, 0, r'.*\\n[^a-zA-Z]+$(.*)', 0)\n",
        "    extract_info(result, tuple_array, 0, 2, 4, 5, data_emissao, file_name, is_image, \"Itaú\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_carteira_detalhada_itau(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Atualizado em )\\d{2}\\/\\d{2}\\/\\d{4}\\s*(?=Hist.rico de Rentabilidade)'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter o bloco onde estão os ativos\n",
        "    pattern = r'(?<=Carteira detalhada).*(?=Histórico de Rentabilidade)'\n",
        "    ativos_text = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos\n",
        "    pattern = r'(^.*?)\\s*([\\d.]+\\,\\d{2})\\s*[\\d]+\\,\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, ativos_text, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 1, None, None, data_emissao, file_name, is_image, \"Itaú\", noise_config)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def obtem_posicao_consolidada_itau(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Define a configuração para remoção de ruídos do nome do ativo\n",
        "    noise_config = {\"text\": text_pdfminer, \"config\": Config.REMOVE_FROM_LEFT }\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=emitido em )\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos\n",
        "    pattern = r'((.*\\n){3,8}.*)\\s*(R\\$\\s*[\\d.]+\\,\\d{2}\\s*[\\d,.]+\\%){5}([\\d.]+\\,\\d{2})'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 3, None, None, data_emissao, file_name, is_image, \"Itaú\", noise_config)\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_movimentacao_bradesco(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Até\\:)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o nome do ativo\n",
        "    pattern = r'(Produto|Nome do Fundo): (.*)\\s*(.|\\n)*Total saldo atual\\s*([\\d.,]+)\\s*([\\d.,]+)\\s*([\\d.,]+)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE))\n",
        "\n",
        "    if regex.search(r'Vlr\\s*Princ\\.\\s*\\(R\\$\\)\\s*Vlr\\.\\s*Bruto\\s*\\(R\\$\\)', text_pypdf, flags=(regex.IGNORECASE)):\n",
        "        extract_info(result, tuple_array, 1, 4, None, None, data_emissao, file_name, is_image, \"Bradesco\")\n",
        "    elif regex.search(r'Valor\\s*da\\s*Cota\\s*Vlr\\.\\s*Bruto\\s*\\(R\\$\\)', text_pypdf, flags=(regex.IGNORECASE)):\n",
        "        extract_info(result, tuple_array, 1, 5, None, None, data_emissao, file_name, is_image, \"Bradesco\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_relatorio_carteira_santander(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Data da P osição: )\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos de Renda Fixa\n",
        "    pattern = r'\\d{2}\\/\\d{2}\\/\\d{2}\\s*(.*?)(\\(*\\d+\\,\\d+\\s*(.|\\n)*?)\\)*\\d{2}\\/\\d{2}\\/\\d{2}\\s*(\\d{2}\\/\\d{2}\\/\\d{2})\\s*([\\-\\d\\,\\.]+\\s*){4}([\\-\\d\\,\\.]+)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    tuple_array = gera_ativo_santander(tuple_array, 0, text_pypdf, text_pdfminer, [0, 5, 3, 1])\n",
        "    extract_info(result, tuple_array, 0, 5, 3, 1, data_emissao, file_name, is_image, \"Santander\")    \n",
        "\n",
        "    pattern = r'(\\%((?!\\d{2}\\/\\d{2}).|\\n)*?)([\\d\\.]+\\,[\\d]+\\s*){4}([\\d\\.]+\\,[\\d]+)\\s*([\\d\\.]+\\,[\\d]+\\s*){2}[\\d.\\%]+\\s*[\\d.]+'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    apply_regex_at_position(tuple_array, 0, r'.*(\\%)(.*)', 1)\n",
        "    apply_regex_at_position(tuple_array, 0, r'.*Total(.*)', 0)\n",
        "    tuple_array = gera_ativo_santander(tuple_array, 0, text_pypdf, text_pdfminer, [0, 3])\n",
        "    extract_info(result, tuple_array, 0, 3, None, None, data_emissao, file_name, is_image, \"Santander\")\n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_portfolio_investimentos_bb(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=\\d{2}\\/\\d{2}\\/\\d{4}\\s*até\\s*)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos de Renda Fixa\n",
        "    # pattern = r'^(I\\s+?)?(.+?)\\s*([\\d.]+\\,\\d{2}\\s*){3}([\\d.]+\\,\\d{2})\\s*([\\d.]+\\,\\d{2}\\s*){2}([\\d]+\\.[\\d]+)'\n",
        "    # tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    # tuple_array = obtem_ativos_ate_100_por_cento(tuple_array, 5)\n",
        "    # extract_info(result, tuple_array, 1, 3, None, None, data_emissao, file_name, is_image, \"BB\")    \n",
        "\n",
        "    pattern = r'^([A-Z](((?!\\d{2}\\/\\d{2}\\/\\d{4}).)*))\\d{2}\\/\\d{2}\\/\\d{4}\\s*([\\d\\.\\,]+\\d+\\s*){6}([\\d\\.\\,]+\\,\\d{2})\\s*([\\d\\.\\,]+\\d+)'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "    extract_info(result, tuple_array, 0, 4, None, None, data_emissao, file_name, is_image, \"BB\")  \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_cliente_bb(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=\\-\\s*)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para cortar apenas o trecho de interesse do extrato\n",
        "    pattern = r'(?<=Saldo por fundo).*(?=Rendimento por Fundo)'\n",
        "    text_pypdf = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter os ativos\n",
        "    pattern = r'^([A-Z].*?)\\s*[\\d\\.]+\\,\\d+\\s*([\\d\\.]+\\,\\d+)\\s*[\\d\\.]+\\,\\d+\\s*'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 1, None, None, data_emissao, file_name, is_image, \"BB\")  \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_cliente_icatu(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Data da impressão: )\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o número do certificado\n",
        "    pattern = r'(?<=Extrato Cert\\.\\s)\\d+'\n",
        "    certificado = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o valor bruto do extrato\n",
        "    pattern = r'(?<=Saldo Bruto em ' + data_emissao.replace('/','\\/') + r'\\sR\\$\\s)[\\d\\.]+\\,\\d{2}'\n",
        "    saldo_bruto = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o valor bruto do extrato\n",
        "    pattern = r'(?<=\\d{2}\\/\\d{2}\\/\\d{4}\\s*R\\$\\s*[\\d.]+\\,\\d{2}\\s*[\\d.]+\\,\\d+\\s*[\\d.]+\\,\\d+\\s*Cert.\\s*' + certificado + r'\\s+).+(?=(ENTRADA|SAIDA))'\n",
        "    nome_ativo = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE))\n",
        "\n",
        "    # Gera o resultado da extração\n",
        "    tuple_array = [(\"Cert. \" + certificado, saldo_bruto)]\n",
        "\n",
        "    # Atualiza o nome do ativo caso tenha sido encontrado\n",
        "    if nome_ativo:\n",
        "        tuple_array = [(nome_ativo.group(0) + \" - Cert. \" + certificado, saldo_bruto)]\n",
        "\n",
        "    # Extrai as informações encontradas\n",
        "    extract_info(result, tuple_array, 0, 1, None, None, data_emissao, file_name, is_image, \"Icatu\")  \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_sulamerica(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Emiss.o:\\s*)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter o nome do ativo\n",
        "    pattern = r'(?<=Rentabilidade\\s*Acumulada\\s*\\(\\%\\)\\s*)[A-Z].*?(?=Peri.dico\\s*para)'\n",
        "    nome_ativo = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter o a informação de PGBL ou VGBL\n",
        "    pattern = r'((PGBL|VGBL).*?|((?!PGBL|VGBL).)*?)(?=Emiss.o:\\s*)'\n",
        "    tuple_result = regex.findall(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL))\n",
        "\n",
        "    # Etapa para padronizar resultados que são um array simples e os que são array de tuplas\n",
        "    tuple_result = get_first_tuple(tuple_result)\n",
        "    \n",
        "    # Obtém o complemento do ativo\n",
        "    complemento_ativo = \"\" if len(tuple_result) < 2 else (tuple_result[1].strip().upper() + \" - \")\n",
        "\n",
        "    # Regex para obter o valor bruto do extrato\n",
        "    pattern = r'(?<=Saldo\\s*atual\\s*R\\$\\s*)[\\d.]+\\,\\d{2}'\n",
        "    saldo_bruto = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Gera o resultado da extração\n",
        "    tuple_array = [(complemento_ativo + nome_ativo, saldo_bruto)]\n",
        "\n",
        "    # Extrai as informações encontradas\n",
        "    extract_info(result, tuple_array, 0, 1, None, None, data_emissao, file_name, is_image, \"SulAmérica\")  \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_extrato_posicao_detalhada_bradesco(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Posi..o\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*Movimenta..es\\s*Posi..o\\s*)(\\d{2}\\/\\d{2}\\/\\d{4})'\n",
        "    data_emissao = regex.search(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE)).group(0)\n",
        "\n",
        "    # Regex para obter ativos de RENDA FIXA\n",
        "    pattern = r'(^.*?)(\\d{2}\\/\\d{2}\\/\\d{2}\\s*){2}(\\d{2}\\/\\d{2}\\/\\d{2})\\s*\\(?[\\d.]+\\,\\d{2}\\)?\\s*\\(?(.*?[\\d.]+?\\,\\d{2})\\)?\\s*(\\(?[\\d.]+\\,\\d{2}\\)?\\s*){2}\\(?([\\d.]+\\,\\d{2})\\)?(\\s*\\(?[\\d.]+\\,\\d+\\)?){3}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    \n",
        "    # Adiciona o \"% a.a.\" ao fim do indexador e remove os que forem \"0,00 % a.a.\"\n",
        "    tuple_array = [[item[0], item[5], item[2], item[3] + \"% a.a.\"] for item in tuple_array]\n",
        "    apply_regex_at_position(tuple_array, 3, r'^(.*?)(?=0,00|$)', 0)\n",
        "    extract_info(result, tuple_array, 0, 1, 2, 3, data_emissao, file_name, is_image, \"Bradesco\")  \n",
        "\n",
        "    # Regex para obter ativos de MULTIMERCADO\n",
        "    pattern = r'(^.*?)\\d{2}\\/\\d{2}\\/\\d{2}(\\s*[\\d.]+\\,\\d+){3}\\s*([\\d.]+\\,\\d+)(\\s*[\\d.]+\\,\\d+){3}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"Bradesco\")\n",
        "\n",
        "    # Regex para obter ativos de REAL STATE\n",
        "    pattern = r'(^((?!\\d{2}\\/\\d{2}\\/\\d{2}|\\,\\d{2}).)*)[\\d]+?\\s+[\\d.]+?\\,\\d{2}\\s+[\\d.]+?\\,\\d{2}\\s+([\\d.]+?\\,\\d{2})\\s+[\\d.]+?\\,\\d{2}\\s+[\\d.]+?\\,\\d{2}'\n",
        "    tuple_array = regex.findall(pattern, text_pypdf, flags=(regex.IGNORECASE | regex.MULTILINE))\n",
        "    extract_info(result, tuple_array, 0, 2, None, None, data_emissao, file_name, is_image, \"Bradesco\")        \n",
        "\n",
        "    return result\n",
        "\n",
        "def obtem_posicao_cotista_btg(file_name, text_pypdf, text_pdfminer, is_image):\n",
        "\n",
        "    # Cria o array resultante\n",
        "    result = []\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    pattern = r'(?<=Data\\s*da\\s*posi..o\\s*\\:\\s*)\\d{2}\\/\\d{2}\\/\\d{4}'\n",
        "    data_emissao = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o nome do ativo\n",
        "    pattern = r'(?<=de\\s*cotistas).*(?=Conta\\s*do\\s*fundo)'\n",
        "    nome_ativo = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE | regex.MULTILINE | regex.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter o valor bruto do extrato\n",
        "    pattern = r'(?<=Saldo\\s*bruto\\s*\\(R\\$\\)\\s*\\:\\s*)[\\d,.]+\\,\\d{2}'\n",
        "    saldo_bruto = regex.search(pattern, text_pdfminer, flags=(regex.IGNORECASE)).group(0)\n",
        "\n",
        "    # Extrai as informações encontradas\n",
        "    extract_info(result, [(nome_ativo, saldo_bruto)], 0, 1, None, None, data_emissao, file_name, is_image, \"BTG Pactual\")  \n",
        "\n",
        "    return result\n",
        "    \n",
        "def execute_extraction(file_name, text_pypdf, text_pdfminer, text_images):\n",
        "    \n",
        "    # Por padrão, assumiremos que não é uma imagem\n",
        "    is_image = False\n",
        "\n",
        "    # Verifica se o pdf obtido na verdade é uma imagem\n",
        "    if len(text_pdfminer) < 99 and len(text_pypdf) < 99:\n",
        "        text_pypdf, text_pdfminer = text_images, text_images\n",
        "        print(\"PDF de imagem detectado.\")\n",
        "        is_image = True\n",
        "\n",
        "    # Obtém o header a ser utilizado\n",
        "    text_header = text_pdfminer if len(text_pdfminer) > 99 else text_pypdf\n",
        "\n",
        "    # Verifica se há caracteres mínimos\n",
        "    if len(text_header) > 99:\n",
        "        \n",
        "        # Define a quantidade de caracteres máxima a ser analisada no header\n",
        "        superior_limit = 200 if len(text_header) > 200 else len(text_header)\n",
        "\n",
        "        # Armazena os primeiros caracteres do pdf\n",
        "        text_header = regex.sub('\\s+','', text_header[0:superior_limit].lower())\n",
        "\n",
        "        print(text_header)\n",
        "\n",
        "        # Mapeia todos os métodos de extração de acordo com uma expressão regular\n",
        "        extracoes_map = [\n",
        "            (r'extratodecotista', obtem_extrato_cotista_xp),\n",
        "            (r'posi..o&performance', obtem_posicao_performance_xp),\n",
        "            (r'posi..oconsolidadadatada', obtem_posicao_consolidada_xp),\n",
        "            (r'contaxp.*?c.digo.*?investimentos.*?assessordeinv', obtem_posicao_consolidada_xp),\n",
        "            (r'extratoconsolidadoinvestimentos.*saldos', obtem_extrato_consolidado_modal),\n",
        "            (r'dispon.velparainvestirr\\$[\\d.,]+aliquidar', obtem_posicao_consolidada_genial),\n",
        "            (r'carteiradeinvestimentos', obtem_carteira_investimentos_itau),\n",
        "            (r'nomeclienteresumosaldoparaaplica..o', obtem_carteira_detalhada_itau),\n",
        "            (r'posi..oconsolidadatipodeinvest', obtem_posicao_consolidada_itau),\n",
        "            (r'extratodemovimentaçãonome', obtem_extrato_movimentacao_bradesco),\n",
        "            (r'santander.*?relat.riodecarteira', obtem_relatorio_carteira_santander),\n",
        "            (r'sistemadeinforma..esbancodobrasil', obtem_extrato_cliente_bb),\n",
        "            (r'extratocert.*?dadosdocliente', obtem_extrato_cliente_icatu),\n",
        "            (r'portf.liodeinvestimento', obtem_portfolio_investimentos_bb),\n",
        "            (r'sulam.rica.*emiss.o', obtem_extrato_sulamerica),\n",
        "            (r'posi..ode\\d{2}\\/\\d{2}\\/\\d{4}.*estoquetotal', obtem_extrato_diario_modal),\n",
        "            (r'prezado.*?sr.*?ag\\:.*?conta\\:.*?', obtem_extrato_posicao_detalhada_bradesco),\n",
        "            (r'cotistas.*?contadofundo\\:\\d+contadocotista', obtem_posicao_cotista_btg),\n",
        "        ]\n",
        "\n",
        "        # Faça a extração de acordo com o método da expressão regular que houver o match\n",
        "        for extracao in extracoes_map:\n",
        "            if regex.search(extracao[0], text_header):\n",
        "                try:\n",
        "                    result = extracao[1](file_name, text_pypdf, text_pdfminer, is_image)\n",
        "                    status = 'SUCCESS' if (len(result) > 0) else 'EMPTY_RESULT'\n",
        "                    return {'Result': result, 'Status': status, 'Message': 'Ativos obtidos com sucesso'}\n",
        "                except Exception as e:\n",
        "                    print(e)\n",
        "                    return {'Result': [], 'Status': 'FATAL_ERROR', 'Message': str(e)}\n",
        "\n",
        "    return {'Result': [], 'Status': 'UNMAPPED', 'Message': 'Extrato não mapeado pelo extrator'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErVV5risLq03"
      },
      "outputs": [],
      "source": [
        "def main(req: func.HttpRequest) -> func.HttpResponse:\n",
        "\n",
        "    # Marca o tempo de início do método\n",
        "    inicio = time.time()\n",
        "\n",
        "    # Obtém a requisição \n",
        "    request_data = req.get_json()\n",
        "\n",
        "    # Cria o objeto de resposta da requisição\n",
        "    response = {'Status': 'SUCCESS', 'Message': '', 'FileStatus': [], 'Value': ''}\n",
        "\n",
        "    # Verifica se a requisição veio no formato correto\n",
        "    if not is_valid_request(response, request_data, ['Files', 'Environment']):\n",
        "        return func.HttpResponse(json.dumps(response), mimetype='application/json')\n",
        "\n",
        "    # Variáveis para armazenar os ativos coletados e os base64 já extraidos\n",
        "    result, base64_history = [], []\n",
        "\n",
        "    # Atualiza a variável global que contém a lista de FIIs e classificações\n",
        "    get_dex_rules(request_data['Environment'])\n",
        "\n",
        "    # Percorre cada um dos arquivos do array\n",
        "    for res in request_data['Files']:\n",
        "\n",
        "        # Verifica se um nome de arquivo foi informado\n",
        "        if 'FileName' not in res:\n",
        "            continue\n",
        "        \n",
        "        # Obtém o nome do arquivo\n",
        "        file_name = res['FileName']\n",
        "        print(f'Processing file \"{file_name}\"...')\n",
        "\n",
        "        # Verifica se um base64 foi informado\n",
        "        if 'Value' not in res:\n",
        "            extraction_result = {'Status': 'NO_CONTENT', 'Message': 'Nenhum base64 foi informado'}\n",
        "            update_file_status(response, file_name, extraction_result)\n",
        "            continue\n",
        "\n",
        "        # Verifica se o base64 em questão já foi lido anteriormente\n",
        "        if res['Value'] in base64_history:\n",
        "            extraction_result = {'Status': 'DUPLICATED', 'Message': 'Arquivo duplicado'}\n",
        "            update_file_status(response, file_name, extraction_result)\n",
        "            continue\n",
        "\n",
        "        # Adiciona o base64 em questão no histórico\n",
        "        base64_history.append(res['Value'])\n",
        "\n",
        "        # Converte o conteúdo do base64 para um arquivo temporário\n",
        "        temp_file = convert_base64_to_file(res['Value'], 'pdf')\n",
        "\n",
        "        # Retorna um erro caso o pdf em questão possua senha\n",
        "        if pdf_requires_password(temp_file):\n",
        "            extraction_result = {'Status': 'ACCESS_DENIED', 'Message': 'Arquivo com senha'}\n",
        "            update_file_status(response, file_name, extraction_result)\n",
        "            continue\n",
        "\n",
        "        # Obtém o texto presente no pdf \n",
        "        text_pypdf, text_pdfminer, text_images = read_pdf_file_content(temp_file)\n",
        "\n",
        "        # Executa a extração do PDF\n",
        "        extraction_result = execute_extraction(file_name, text_pypdf, text_pdfminer, text_images)\n",
        "\n",
        "        # Se ocorreu sucesso, concatena com o consolidado geral\n",
        "        if (extraction_result['Status'] == 'SUCCESS'):\n",
        "            result = result + extraction_result['Result']\n",
        "\n",
        "        # Atualiza o status de extração do arquivo atual\n",
        "        update_file_status(response, file_name, extraction_result)\n",
        "\n",
        "    # Caso o tamanho do DataFrame seja maior que zero, retorna o base64 do consolidado\n",
        "    if (len(result) > 0):\n",
        "        response['Value'] = json_to_excel(result)\n",
        "\n",
        "    # Exibe quantos MS demoraram para execução do método\n",
        "    total_time = time.time() - inicio\n",
        "    print(f'Runtime: {total_time:.2f} sec')\n",
        "    response['Runtime'] = round(total_time, 3)\n",
        "\n",
        "    return func.HttpResponse(json.dumps(response), mimetype='application/json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TtJL4jz2rLP"
      },
      "outputs": [],
      "source": [
        "# Classe que simula um request feito via azure functions\n",
        "class AzureRequest:\n",
        "    def get_json(self):\n",
        "        response = {'Files': [], 'Environment': 'Dev'}\n",
        "        for file in file_objects.keys():\n",
        "            with open(file, \"rb\") as f:\n",
        "                pdf_content = f.read()\n",
        "                base64_pdf_content = base64.b64encode(pdf_content)\n",
        "                response['Files'].append({\n",
        "                    'FileName': file,\n",
        "                    'Value': base64_pdf_content\n",
        "                })\n",
        "        return response\n",
        "\n",
        "azureRequest = AzureRequest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8eYopxUg_oy",
        "outputId": "5af42c3f-0a64-4685-8177-7ccda166be8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file \"- Posicao Consolidada XP - 55432.pdf\"...\n",
            "________senusadministracaodebenseparticipacoes_históricoposiçãoconsolidadadatadaconsulta:10/10/202218:37downloadfeitopor:a4909contaxpcontaxpcódigoassessordeinvest\n",
            "Processing file \"Brad FIC FI RF Infl Curta.pdf\"...\n",
            "extratodemovimentaçãonomedofundo:bradescoficfirfinflaçãocurtacnpjdofundo:32.742.742/0001-89dataemissãodoextrato:10/07/2022apartirde:01/06/2022até:08/07/2022rentabilida\n",
            "Processing file \"Brad Invest Facil.pdf\"...\n",
            "extratodemovimentaçãonome:elisangelaferreiramartinsconta:agência:6592|conta:456073-6tipodeinvestimento:cdb-certificadodedepósitobancáriodataemissãodoextrato:10/07/2022a\n",
            "Processing file \"BRADESCO PRIVATE BANK - Relatório de Investimentos Mensal (senha 0745).pdf\"...\n",
            "Processing file \"bradesco sem senha.pdf\"...\n",
            "prezado(a)sr(a):joaobatistadasilveiraag:1233conta:387884-8ref.:janeiro/2023apresentamosnaspróximaspáginasseurelatóriodeinvestimentosdomêsdejaneiro/2023.lembre-se:desdeoin\n",
            "Processing file \"BTG PACTUAL - Posição de Cotistas.pdf\"...\n",
            "PDF de imagem detectado.\n",
            "ãodecotistasatmosacoesfcfiacontadofundo:001714605contadocotista:001660675distribuidor:atmoscapitalgestaoderecursosltdarendimento(%):420,45saldodecotas:3.506,62415575\n",
            "Processing file \"Carteira Itau - Veronica.pdf\"...\n",
            "5900|xxx84-6carteiradeinvestimentosagosto2022brunoalvesdebelmontpessoaespecialistaemgestãodepatrimônioe-mail:bruno.pessoa@itau-unibanco.com.brtel.:3003-51241posiçãoeper\n",
            "Processing file \"Extrato BB - Cliente 03.pdf\"...\n",
            "sisbb-sistemadeinformaçõesbancodobrasil-29/11/2022-autoatendimentobb-17:59:51agência:4852-6conta:8269-4cliente:marcoaureliocastromelodadosgeraisnomecpf0matrí\n",
            "Processing file \"Extrato BB 2 - Cliente 03.pdf\"...\n",
            "sisbb-sistemadeinformaçõesbancodobrasil-29/11/2022-autoatendimentobb-18:00:54agência:4852-6conta:8269-4cliente:marcoaureliocastromelodadosgeraisnomecpfsdasfaf\n",
            "Processing file \"Extrato Icatu - Cliente 03.pdf\"...\n",
            "extratocert.000002626251datadaimpressão:29/11/202217:49:24dadosdoclientenomeclientevalor(r$)valordacotasaldobrutoem28/10/2022r$7.412,341,22744460movimentaçõesdeentr\n",
            "Processing file \"Extrato Icatu 2 - Cliente 03.pdf\"...\n",
            "extratocert.000001745465datadaimpressão:29/11/202217:48:56dadosdoclientenomeclienteperíodode29/10/2022até29/11/2022valor(r$)valordacotaqtd.decotassaldobrutoem28/1\n",
            "Processing file \"Extrato Itau - Cliente 02.pdf\"...\n",
            "nomedoclientecpfagênciaqwqw7contacorrentexxxxx-1posiçãoconsolidadatipodeinvestimentofundosdeinvestimentodistribuição91,46%emitidoem31/10/2022às15:59:50valorinvestido\n",
            "Processing file \"Extrato Itau - Cliente 06.pdf\"...\n",
            "nomeclienteresumosaldoparaaplicação:r$6.292,02corretora:semcadastrosaldototaldacarteira:r$9.684.892,43perfildoinvestidorseuperfilderiscoconservadormoderadoarrojado\n",
            "Processing file \"Extrato XP - Cliente 01.pdf\"...\n",
            "extratodecotistaconsolidadomovimentaçãode15/05/2022a11/11/2022nomedoclienteendereçocep:02440-00posiçãoconsolidadafundocotaquantidadevaloraplicadovalorbrutoirsulamé\n",
            "Generating Excel file...\n",
            "Runtime: 49.83 sec\n"
          ]
        }
      ],
      "source": [
        "response = json.loads(main(azureRequest)._HttpResponse__body.decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXnQztTW4d2h",
        "outputId": "8c50ee1c-19d2-4720-bc6b-4cf4283b9336"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Status': 'SUCCESS',\n",
              " 'Message': '',\n",
              " 'FileStatus': [{'FileName': '- Posicao Consolidada XP - 55432.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Brad FIC FI RF Infl Curta.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Brad Invest Facil.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'BRADESCO PRIVATE BANK - Relatório de Investimentos Mensal (senha 0745).pdf',\n",
              "   'Status': 'ACCESS_DENIED',\n",
              "   'Message': 'Arquivo com senha'},\n",
              "  {'FileName': 'bradesco sem senha.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'BTG PACTUAL - Posição de Cotistas.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Carteira Itau - Veronica.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato BB - Cliente 03.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato BB 2 - Cliente 03.pdf',\n",
              "   'Status': 'EMPTY_RESULT',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato Icatu - Cliente 03.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato Icatu 2 - Cliente 03.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato Itau - Cliente 02.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato Itau - Cliente 06.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'},\n",
              "  {'FileName': 'Extrato XP - Cliente 01.pdf',\n",
              "   'Status': 'SUCCESS',\n",
              "   'Message': 'Ativos obtidos com sucesso'}],\n",
              " 'Value': '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',\n",
              " 'Runtime': 49.829}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hY1gCbc7L2ay",
        "outputId": "8537cee6-ae6f-4673-d852-7e4856d1e343"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db2176a2-2580-431c-a9f7-b7e715101635\", \"Ativos.xlsx\", 11166)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if response['Value'] != '':\n",
        "\n",
        "    f = open(\"Ativos.xlsx\", 'wb')\n",
        "    f.write(base64.b64decode(response['Value'], validate=True))\n",
        "    f.close()\n",
        "    \n",
        "    files.download(\"Ativos.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "VkToatQA1VSo",
        "outputId": "9c8293bf-cb69-4434-92a0-e5cc4ee5fe4d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69ad9e6d-9fa5-4e72-94a9-06432f4b1f85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69ad9e6d-9fa5-4e72-94a9-06432f4b1f85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Posicao Consolidada XP - 55414 (IMAGEM).png to Posicao Consolidada XP - 55414 (IMAGEM) (2).png\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "image_objects = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install ocropy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAjfqv90hWFK",
        "outputId": "dccbb324-afe1-440e-df7a-e46350385832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement ocropy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ocropy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import ocrolib\n",
        "from ocrolib import tesseract\n",
        "\n",
        "for image_path in image_objects.keys():\n",
        "\n",
        "    image = plt.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "    # Converte a imagem em escala de cinza\n",
        "    gray_image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "\n",
        "    # Realiza o OCR\n",
        "    result = tesseract.image_to_string(gray_image)\n",
        "\n",
        "    # Imprime o texto extraído\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "xfCNbKR8hVHu",
        "outputId": "c9b076c9-17f5-46f5-ed23-b5cb281e5f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fcae7d0dad3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mocrolib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mocrolib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesseract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ocrolib'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMSkLMyB8PGt",
        "outputId": "7a81344a-780e-4525-eaf2-7a128b2ef8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: msrest in /usr/local/lib/python3.9/dist-packages (0.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from msrest) (1.3.1)\n",
            "Requirement already satisfied: azure-core>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from msrest) (1.26.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from msrest) (2022.12.7)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from msrest) (0.6.1)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.9/dist-packages (from msrest) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from azure-core>=1.24.0->msrest) (4.5.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from azure-core>=1.24.0->msrest) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest) (4.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.5.0->msrest) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: azure-ai-formrecognizer in /usr/local/lib/python3.9/dist-packages (3.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from azure-ai-formrecognizer) (4.5.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in /usr/local/lib/python3.9/dist-packages (from azure-ai-formrecognizer) (1.26.3)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.9/dist-packages (from azure-ai-formrecognizer) (1.1.28)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.9/dist-packages (from azure-ai-formrecognizer) (0.7.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.9/dist-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-formrecognizer) (2.25.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from azure-core<2.0.0,>=1.23.0->azure-ai-formrecognizer) (1.15.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-formrecognizer) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-formrecognizer) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.23.0->azure-ai-formrecognizer) (1.26.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: azure-cognitiveservices-vision-computervision in /usr/local/lib/python3.9/dist-packages (0.9.0)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.9/dist-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\n",
            "Requirement already satisfied: msrest>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from azure-cognitiveservices-vision-computervision) (0.7.1)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2022.12.7)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.25.1)\n",
            "Requirement already satisfied: azure-core>=1.24.0 in /usr/local/lib/python3.9/dist-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.5.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install msrest\n",
        "!pip install azure-ai-formrecognizer\n",
        "!pip install azure-cognitiveservices-vision-computervision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.formrecognizer import FormRecognizerClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "for image_path in image_objects.keys():\n",
        "    # Define suas credenciais do Azure\n",
        "    SUBSCRIPTION_KEY = 'c82f2d8039744c5c8562505d083f7da8'\n",
        "    ENDPOINT = 'https://forms-recognizer-alocc.cognitiveservices.azure.com/'\n",
        "\n",
        "    # Cria um objeto FormRecognizerClient\n",
        "    credential = AzureKeyCredential(SUBSCRIPTION_KEY)\n",
        "    form_recognizer_client = FormRecognizerClient(ENDPOINT, credential)\n",
        "\n",
        "    # Envia a imagem para análise\n",
        "    with open(image_path, \"rb\") as f:\n",
        "        poller = form_recognizer_client.begin_recognize_receipts(f)\n",
        "    receipts = poller.result()\n",
        "\n",
        "    print(receipts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9zpgPh8dvWU",
        "outputId": "132f30f7-52df-46f2-9c6f-a66514cb0aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RecognizedForm(form_type=prebuilt:receipt, fields={'Items': FormField(value_type=list, label_data=None, value_data=None, name=Items, value=[FormField(value_type=dictionary, label_data=None, value_data=None, name=Items, value={'TotalPrice': FormField(value_type=float, label_data=None, value_data=FieldData(page_number=1, text=62.913,06 R$ 61.530,45, bounding_box=[Point(x=1180.0, y=781.3), Point(x=1351.9, y=780.0), Point(x=1352.0, y=800.5), Point(x=1180.1, y=801.8)], field_elements=None), name=TotalPrice, value=None, confidence=0.228)}, confidence=1.0), FormField(value_type=dictionary, label_data=None, value_data=None, name=Items, value={'Name': FormField(value_type=string, label_data=None, value_data=FieldData(page_number=1, text=BANCO MASTER S/A - OUT/2025, bounding_box=[Point(x=283.0, y=822.0), Point(x=486.0, y=822.0), Point(x=486.0, y=844.0), Point(x=283.0, y=844.0)], field_elements=None), name=Name, value='BANCO MASTER S/A - OUT/2025', confidence=0.0), 'TotalPrice': FormField(value_type=float, label_data=No]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "jax1DSr47-IK",
        "outputId": "60226ecd-bd9f-4f00-bbfd-bc9e353e1975"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor image_path in image_objects.keys():\\n    # Define suas credenciais do Azure\\n    SUBSCRIPTION_KEY = 'c82f2d8039744c5c8562505d083f7da8'\\n    ENDPOINT = 'https://forms-recognizer-alocc.cognitiveservices.azure.com/formrecognizer/v2.1-preview.2/prebuilt/receipt'\\n\\n    # Define o cabeçalho da solicitação\\n    headers = {\\n        'Content-Type': 'image/jpeg',\\n        'Ocp-Apim-Subscription-Key': SUBSCRIPTION_KEY\\n    }\\n\\n    # Realiza a solicitação de análise do recibo\\n    with open(image_path, 'rb') as f:\\n        response = requests.post(ENDPOINT, headers=headers, data=f)\\n\\n    # Recupera os resultados da análise\\n    if response.status_code == 202:\\n        result_url = response.headers['Operation-Location']\\n        response = requests.get(result_url, headers=headers)\\n        results = json.loads(response.content.decode())\\n        print(json.dumps(results, indent=2))\\n    else:\\n        print(response.status_code, response.reason)\\n\\n    # Cria o cliente da API de Visão Computacional do Azure\\n    computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(SUBSCRIPTION_KEY))\\n\\n    # Lê a imagem como bytes usando a classe io.BytesIO\\n    with io.BytesIO() as image_stream:\\n        with open(image_path, 'rb') as image_file:\\n            image_stream.write(image_file.read())\\n        image_stream.seek(0)\\n        # Extrai o texto da imagem usando a API de Visão Computacional do Azure\\n        # result = computervision_client.recognize_printed_text_in_stream(image_stream)\\n\\n        # Extrai o texto da imagem na orientação horizontal e vertical usando a API de Visão Computacional do Azure\\n        result = computervision_client.recognize_printed_text_in_stream(image_stream,  language='pt')\\n\\n    # Exibe o texto extraído da imagem\\n    if len(result.regions) == 0:\\n        print('Nenhum texto encontrado na imagem.')\\n    else:\\n        for region in result.regions:\\n            for line in region.lines:\\n                print(' '.join([word.text for word in line.words]))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\"\"\"\n",
        "for image_path in image_objects.keys():\n",
        "    # Define suas credenciais do Azure\n",
        "    SUBSCRIPTION_KEY = 'c82f2d8039744c5c8562505d083f7da8'\n",
        "    ENDPOINT = 'https://forms-recognizer-alocc.cognitiveservices.azure.com/formrecognizer/v2.1-preview.2/prebuilt/receipt'\n",
        "\n",
        "    # Define o cabeçalho da solicitação\n",
        "    headers = {\n",
        "        'Content-Type': 'image/jpeg',\n",
        "        'Ocp-Apim-Subscription-Key': SUBSCRIPTION_KEY\n",
        "    }\n",
        "\n",
        "    # Realiza a solicitação de análise do recibo\n",
        "    with open(image_path, 'rb') as f:\n",
        "        response = requests.post(ENDPOINT, headers=headers, data=f)\n",
        "\n",
        "    # Recupera os resultados da análise\n",
        "    if response.status_code == 202:\n",
        "        result_url = response.headers['Operation-Location']\n",
        "        response = requests.get(result_url, headers=headers)\n",
        "        results = json.loads(response.content.decode())\n",
        "        print(json.dumps(results, indent=2))\n",
        "    else:\n",
        "        print(response.status_code, response.reason)\n",
        "\n",
        "    # Cria o cliente da API de Visão Computacional do Azure\n",
        "    computervision_client = ComputerVisionClient(ENDPOINT, CognitiveServicesCredentials(SUBSCRIPTION_KEY))\n",
        "\n",
        "    # Lê a imagem como bytes usando a classe io.BytesIO\n",
        "    with io.BytesIO() as image_stream:\n",
        "        with open(image_path, 'rb') as image_file:\n",
        "            image_stream.write(image_file.read())\n",
        "        image_stream.seek(0)\n",
        "        # Extrai o texto da imagem usando a API de Visão Computacional do Azure\n",
        "        # result = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "        # Extrai o texto da imagem na orientação horizontal e vertical usando a API de Visão Computacional do Azure\n",
        "        result = computervision_client.recognize_printed_text_in_stream(image_stream,  language='pt')\n",
        "\n",
        "    # Exibe o texto extraído da imagem\n",
        "    if len(result.regions) == 0:\n",
        "        print('Nenhum texto encontrado na imagem.')\n",
        "    else:\n",
        "        for region in result.regions:\n",
        "            for line in region.lines:\n",
        "                print(' '.join([word.text for word in line.words]))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbM-6T9onJW_",
        "outputId": "e2f7fcdf-c509-4152-f1fe-b0dd1ffe57ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "investimentos\n",
            "\n",
            " \n",
            "\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "\n",
            "“Histórico Posição Consolidada\n",
            "\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "\n",
            "Conta XP\n",
            "\n",
            "Código Assessor de Investimentos\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "\n",
            "Data da posição histórica\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "20.2%. RENDA FIXA\n",
            "\n",
            "  \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "A ,\n",
            "1% INFLAÇÃO\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "POSIÇÃO\n",
            "R$ 166.139,90\n",
            "\n",
            " \n",
            "\n",
            "VALOR VALOR\n",
            "ATIVO APLICAÇÃO CARÊNCIA VENCIMENTO TAXA DISPONÍVEL GARANTIA APLICADO POSIÇÃO LíquDo\n",
            "CDBAGIBANK- JUL/2024 14/07/2021 13/07/2024 13/07/2024 IPC-A+505% 56 o R$0,00 R$62.91306  R$61.530,45\n",
            "CDB BANCO MASTER S/A - OUT/2025 04/10/2021 03/10/2025 03/10/2025 IPC-A+615% 61 0 R$0,00 R$66.367,72  R$65.159,98\n",
            "CDBAGIBANK-AGO/2025 02/08/2021 01/08/2025 01/08/2025 IPC-A+5,70% 33 o R$0,00 R$36.859,12  R$36.087,30\n",
            "FU POSIÇÃO\n",
            "NDOS DE INVESTIMENTO R$ 545.870,40.\n",
            "88%) FUNDOS DE RENDA FIXA PÓS-FIXADO\n",
            "ATIVO DATACOTA VALORCOTA QTD. COTAS EMCOTIZAÇÃO POSIÇÃO VALORLÍQUIDO\n",
            "XP CRÉDITO ESTRUTURADO 360 FI FIMCP 31/03/2022 1,39722880 22927.95993361 R$0,00 R$32.035,61 R$31.859,37\n",
            "JIVE BOSSANOVA HIGH YIELD ADVISORY FIC FIM CP 31/03/2022 101,64192375 400 R$0,00 R$40.656,77 R$ 40.509,00\n",
            "FUNDOS MULTIMERCADOS\n",
            "ATIVO DATACOTA VALORCOTA QTD.COTAS EMCOTIZAÇÃO POSIÇÃO VALOR LÍQUIDO\n",
            "KAPITALO KAPPA ADVISORY FIC FIM 31/03/2022 1,51943110 62631.40083283 R$0,00 R$95.16410 R$94,261,74\n",
            "ABSOLUTE VERTEX ADVISORY FIC FIM 31/03/2022 1,35336128 19253.16192573 R$0,00 R$ 26.056,48 R$25.752,31\n",
            "KINEA ATLASII FIM 31/03/2022 1,76634100 58113.23787568 R$0,00 R$ 102.647,79 R$101.65095\n",
            "FUNDOS DE RENDA VARIÁVEL\n",
            "ATIVO DATACOTA VALORCOTA QTD. COTAS EMCOTIZAÇÃO POSIÇÃO VALOR LÍQUIDO\n",
            "ALASKA BLACK FIC FIA-BDR NÍVEL! 31/03/2022 2,91061840 1162.494505 R$0,00 R$3.383,58 R$3.383,58\n",
            "MILES ACER LONG BIAS ADMSORY FIC FIM 31/03/2022 1,32693346 28496.24435172 R$0,00 R$37.81262 R$36.640,73\n",
            "IP-PARTICIPAÇÕES IPG FIC FIA BOR NÍVEL | 31/03/2022 4,15853682 1497.53492722 R$0,00 R$6.227,55 R$ 6.043,42\n",
            "Rm “Histórico Posição Consolidada\n",
            "é, Investimentos Data da Consulta: 02/0\n",
            "Conta XP\n",
            "\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "\n",
            "Código Assessor de Investimentos\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "\n",
            "Data da posição histórica\n",
            "\n",
            "Pedi\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "ATIVO DATA COTA VALORCOTA | QTD.COTAS EMCOTIZAÇÃO POSIÇÃO VALOR LÍQUIDO\n",
            "DAHLIA TOTAL RETURNFIC FIM 31/03/2022 175676790 8093.29136962 R$0,00 R$1421803 R$13.58533\n",
            "TORKFIC FIA 31/03/2022 144157834  16829.5965612 R$0,00 R$24.26118 — R$24.22500\n",
            "BRASILCAPITAL30 ADVISORY FIC FIA 31/03/2022 300897809  8551.29866777 R$0,00 R$25.73067 — R$25.73067\n",
            "(A\n",
            "16.7% FUNDOS INTERNACIONAIS\n",
            "ATIVO DATACOTA VALORCOTA — QTD.COTAS EMCOTIZAÇÃO POSIÇÃO VALORLÍQUIDO\n",
            "TREND OUROFIM 31/03/2022 208431361  10285.62729024 R$0,00 R$21.43847 R$21.221,90\n",
            "JPMORGAN DÓLAR GLOBAL MACRO OPPORTUNITIES FIM-IE 31/03/2022 160,78900544 308.04559394  R$0,00 R$49.530,34  R$49.530,34\n",
            "MORGAN STANLEY GLOBAL OPPORTUNITIES DOLARADVISORYFICFIAIE 31/03/2022 143,80153040 1050231797 R$0,00 R$15.10249  R$15.10249\n",
            "HASHDEX 40 NASDAQ CRYPTO INDEXFIC FIM 31/03/2022 2,68345360 — 5549.86872756  R$0,00 R$14.89282 R$14.89282\n",
            "TREND BOLSA CHINESA FIM 31/03/2022 0,9727610 21730.11571017 R$000 R$17.32490  R$17.32490\n",
            "WELLINGTON VENTURA 30 ADVISORY FIA IE 31/03/2022  111,66956310 173.61041682  R$000 R$19.387,00  R$19.387,00\n",
            "POSIÇÃO\n",
            "R$ 43.976,00\n",
            "AÇÕES\n",
            "ATIVO QTD.DISPONIVEL  QTD.PROJETADO  QTD.DIA QTD.GARANTIA  QTD.ESTRUTURADOS  QTD.TOTAL  ÚTILMACOTAÇÃO POSIÇÃO\n",
            "VALES 460 o o o 9 460 R$95,60 R$43.976,00\n",
            "\n",
            " \n",
            "\n",
            "Saldo Disponível ..........\n",
            "Garantia ... pa\n",
            "Resgate de Fundo Pendente\n",
            "Resgate de Clube Pendente\n",
            "Temos aVencer ....\n",
            "Utilização de Conta Margem\n",
            "Lançamentos Futuros .\n",
            "01/04/2022 (0+1)\n",
            "04/04/2022 (D+2)\n",
            "05/04/2022 (D+3)\n",
            "(D>3)\n",
            "E Lj\n",
            "\n",
            "   \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "VALOR\n",
            "\n",
            " \n",
            "\n",
            "R$ 40.632,86\n",
            "\n",
            "-. R$000\n",
            "R$27.73918\n",
            "R$000\n",
            "R$000\n",
            "R$000\n",
            "R$000\n",
            "R$000\n",
            "R$0,00\n",
            "R$000\n",
            "R$0,00\n",
            "\n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "  \n",
            "    \n",
            " \n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ],
      "source": [
        "for imagem in image_objects.keys():\n",
        "    text = pytesseract.image_to_string(Image.open(imagem), lang='por')\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUPgcxKio0Q8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Defina a variável `json_content` com o conteúdo do arquivo JSON das suas credenciais\n",
        "json_content = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"ace-vial-380619\",\n",
        "  \"private_key_id\": \"9de688a2a1d6b77757ee4c92d90b3749a9b62f82\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDOlfdUpd1M3iks\\nmfWFpVdBAxhXP6d3iCy8ifOxh2u25ztQ+/biyHiVSvhsD0NYCuXWL5GMErvKGJX/\\n1IvNmm8vU/dNEdgrJxKREmy99FfLlXRTYkyXN1PK0uGJFzpngzy/vMA2SdinUDl8\\nBZwxWJ244EFT86HgIebChISTIQeHdi3zVaZ854Fu5dicY8775ptxmDIWrgNQMU6V\\n4g3zWvEwF3UrYMPw2/oNedX3GiK9EQmrh6JHHIisx94qmZ5Pt6m5v3kPq/iaS4C5\\n9flPZI/ehYJQ46RIZTpQRVVBfX9TRhceIvCiW2PiE8GwZPqZMN9eys0DzGPNL/Er\\nrG3g/XlLAgMBAAECggEAIi+E3zgXV+oHjD7p9zS2LKbzdzSsZMZfCNAXSJBtTbYU\\nBcG8SCj+c04Vr+QSs9YR1JDImBJdiwLoh45HmD1vGrjdWp6SVAnCM8mFvyVZBfJ0\\nbnv8yqU4M38UHVh/rLN18RCuCg3MUVugN5rCDxRn/Tj29oqBhhJ2GkhNm/9CPLMQ\\npPmT/n03fwrxKYssSfVJq+K8FMAYDud/9V8za4lCdNf3iZiwgAwV8+5VnZk50VmX\\njm6b7aSZVOB8WVUfE7P1RODt1a1/RjqYwGoOn7cKbkjie3VQBTh4wZrEIH6RE9jz\\nQ4nVyJM18IKqp/etUBeHCSvPU8dT5m73VRmEmEI9QQKBgQDqtPTOAQNg43+PI8O/\\nGebraOA1WC0Ery3NYExbR9wgxWko97pEmsMK+dR/f2v6Vk67zgHDzSDqzJLOpS8V\\naw0b2uwMpzkMa95c0xMUEcUiF4TT49w+wfyFjHKdQcQe7fN+CDoGxnmYGZg05Xtw\\n1DmxXk2WvzTGcPaRlMkEIq4EawKBgQDhU+awTln3InakAoUPvPLIxLO9NfFcUZGK\\nlWswijIe2tftsj2RwTRjDKbiABNkLh6+ssUNU8DdFGcrYTfSHwSP4XcJ9ZnfXr/g\\noFuo1wq2MN19xGWqQFAoN4YyUNDTpqNTXhGsHwoUBadDXXJG/s1rN7qxMNGxAWrh\\nHEMXvmKWoQKBgQC2gYnO2qjW4XBiTOw8oJaYvY+Cy5MODm4uQlB9tm4sqXUxXxjf\\nmfxKf6RGlD3RhuVoUjO7HroW+oa522a2X+zsmRpuaGYLC6H4SkWOmJbTALjPz2KH\\nBm8nJeRF9krbxipN+XWtqQ4KQPTDRSLsxIosKulobDxMhrCk2a5J4fGxCwKBgEq+\\n9kuN8jIU8J4/Z7xsxWzsM2OUvVgOhuUd48zaSv4JQo/LDLmJCcPBsqpNtCELW4+O\\n5ech3Vx5JDAzs7y0JWNFO6PGISED4Uq2ZzF/BEKjuxW5TLBJXU25/X47aMqNAKjr\\nD5m1QjaaGX4zRXFfnOzwM7ILq8O34KiEI42AzluBAoGAAmMAkOYWyuxeBpNMmxCH\\n7bLZmUFCYV3XOY4tchwylG++ZmD2jxXxWp3jJAlN/JJDvlHwWqbVYU3OiLUiJJ8R\\nCQM6PMcfxZMm7lUc+iwTU3Z7sX1GYQ7c44VcqVxId5rclcAo63FJRwYTfMkYen+7\\nSsMRkCfks0CXGF/BrzD6eJ0=\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"sa-vision-ai-api@ace-vial-380619.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"101018394257672525897\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/sa-vision-ai-api%40ace-vial-380619.iam.gserviceaccount.com\"\n",
        "}\n",
        "\n",
        "# Especifique o caminho e nome do arquivo para salvar o JSON\n",
        "filename =  '/tmp/credentials.json'\n",
        "\n",
        "# Salve o dicionário como um arquivo JSON\n",
        "with open(filename, 'w') as outfile:\n",
        "    json.dump(json_content, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3aM-YPFIdGh"
      },
      "source": [
        "Existem configurações de leitura para google cloud vision equivalente às que temos no pytesseract? Como a \"--psm 6\" e a \"--psm 11\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPoD9cPtVfIs"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "from google.cloud import vision_v1\n",
        "from google.cloud.vision_v1 import types as vision_types\n",
        "\n",
        "# Configure a variável de ambiente GOOGLE_APPLICATION_CREDENTIALS com o caminho para o arquivo JSON das credenciais\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/tmp/credentials.json'\n",
        "\n",
        "# Crie um cliente de visão computacional\n",
        "content = None\n",
        "client = vision_v1.ImageAnnotatorClient()\n",
        "\n",
        "for imagem in image_objects.keys():\n",
        "    # Carregue a imagem em memória\n",
        "    with io.open(imagem, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "image = vision_types.Image(content=content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz6miMi22mL-",
        "outputId": "4cfe26e1-4305-4110-ed0d-276767c7639b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xp investimentos\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "20.2%\n",
            "66.2%\n",
            "D4\n",
            "D30\n",
            "8.29%\n",
            "D60\n",
            ">D60\n",
            "20.1% INFLAÇÃO\n",
            "0%\n",
            "XP Investimentos CCTVM S/A\n",
            "Av. Brigadeiro Faria Lima, 3600 110° andar\n",
            "São Paulo ISP\n",
            "CEP 04538-132\n",
            "CNPJ: 02.332.886/0001-04\n",
            "27.1%\n",
            "xp investimentos\n",
            "13.5%\n",
            "800000\n",
            "750000\n",
            "ATIVO\n",
            "700000\n",
            "650000\n",
            "600000\n",
            "CDBAGIBANK-JUL/2024\n",
            "CDB BANCO MASTER S/A-OUT/2025\n",
            "CDB AGIBANK-AGO/2025\n",
            "8.8% FUNDOS DE RENDA FIXA PÓS-FIXADO\n",
            "ATIVO\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "5.33% AÇÕES\n",
            "MÊS\n",
            "ATIVO\n",
            "Valores no período\n",
            "xp investimentos\n",
            "Ano\n",
            "2022\n",
            "KAPITALO KAPPA ADVISORY FIC FIM\n",
            "ABSOLUTE VERTEX ADVISORY FIC FIM\n",
            "Ano\n",
            "2021\n",
            "XP CRÉDITO ESTRUTURADO 360 FIC FIM CP\n",
            "JIVE BOSSANOVA HIGH YIELD ADVISORY FIC FIM CP\n",
            "KINEA ATLAS II FIM\n",
            "ATIVO\n",
            "XP Investimentos CCTVM S/A_\n",
            "Av. Brigadeiro Faria Lima, 3600 110° andar\n",
            "São Paulo | SP\n",
            "CEP 04538-132\n",
            "CNPJ: 02.332.886/0001-04\n",
            "SPESERY\n",
            "PATRIMÔNIO TOTAL\n",
            "02/2022\n",
            "03/2022\n",
            "Ano\n",
            "2020\n",
            "RENDA FIXA\n",
            "FUNDOS MULTIMERCADOS\n",
            "Ano\n",
            "2019\n",
            "04/2022\n",
            "Ano\n",
            "2018\n",
            "ATIVO\n",
            "TÍTULO\n",
            "ALASKA BLACK FIC FIA-BDR NÍVELI\n",
            "MILES ACER LONG BIAS ADVISORY FIC FIM\n",
            "IP-PARTICIPAÇÕES IPG FIC FIA BDR NÍVEL I\n",
            "ATIVO\n",
            "DAHLIA TOTAL RETURN FIC FIM\n",
            "TORK FIC FIA\n",
            "BRASIL CAPITAL 30 ADVISORY FIC FIA\n",
            "FUNDOS DE RENDA VARIÁVEL\n",
            "xp investimentos\n",
            "PATRIMÔNIO INICIAL\n",
            "R$ 796.730,00\n",
            "FUNDOS DE INVESTIMENTO\n",
            "DISTRIBUIÇÃO DE LIQUIDEZ DA CARTEIRA\n",
            "EVOLUÇÃO PATRIMONIAL\n",
            "16.7% FUNDOS INTERNACIONAIS\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "VALE3 460\n",
            "Saldo Disponível\n",
            "Garantia\n",
            "Resgate de Fundo Pendente\n",
            "Resgate de Clube Pendente\n",
            "Termos a Vencer\n",
            "Utilização de Conta Margem.\n",
            "Lançamentos Futuros\n",
            "XP Investimentos CCTVM S/A\n",
            "Av. Brigadeiro Faria Lima, 3600 | 10° andar\n",
            "São Paulo | SP\n",
            "CEP 04538-132\n",
            "CNPJ: 02.332.886/0001-04\n",
            "Saldo Total Projetado\n",
            "01/04/2022 (D+1)\n",
            "04/04/2022 (D+2)\n",
            "05/04/2022 (D+3)\n",
            "(D>3)\n",
            "SALDO\n",
            "0,00\n",
            "xp investimentos\n",
            "01/2022 794.955,77\n",
            "810.878,75\n",
            "812.634,39\n",
            "10%\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "VARIAÇÃO PATRIMONIAL MENSAL\n",
            "AÇÕES\n",
            "ATIVO QTD. DISPONIVEL QTD. PROJETADO QTD. DIA\n",
            "Jun 21\n",
            "TREND OURO FIM\n",
            "JP MORGAN DÓLAR GLOBAL MACRO OPPORTUNITIES FIM-IE\n",
            "MORGAN STANLEY GLOBAL OPPORTUNITIES DOLAR ADVISORY FIC FIA IE\n",
            "HASHDEX 40 NASDAQ CRYPTO INDEX FIC FIM\n",
            "TREND BOLSA CHINESA FIM\n",
            "WELLINGTON VENTURA 30 ADVISORY FIA IE\n",
            "XP Investimentos CCTVM S/A_\n",
            "Av. Brigadeiro Faria Lima, 3600 110° andar\n",
            "São Paulo | SP\n",
            "CEP 04538-132\n",
            "CNPJ: 02.332.886/0001-04\n",
            "824.358,34\n",
            "PATRIMÔNIO INICIAL\n",
            "(R$)\n",
            "794.955,77\n",
            "Patrimônio @Cunta Corrente\n",
            "Ⓒ Compromissadas\n",
            "780.961,13\n",
            "629.475,49\n",
            "CDB FLUCDB3214BK46\n",
            "656.421,18\n",
            "CDBFLU CDB3218B40B\n",
            "20%\n",
            "Jul 21\n",
            "CDB FLUCDB4210WK9Y\n",
            ">www.xpi.com.br\n",
            "ANGIOMEDICAL SERVICO MEDICO LTDA\n",
            "15.000,00\n",
            "0,00\n",
            "APLICAÇÃO CARÊNCIA VENCIMENTO TAXA\n",
            "13/07/2024 13/07/2024\n",
            "03/10/2025 03/10/2025\n",
            "01/08/2025 01/08/2025\n",
            "14/07/2021\n",
            "0\n",
            "0,00\n",
            "04/10/2021\n",
            "0,00\n",
            "PRÓXIMOS VENCIMENTOS\n",
            "02/08/2021\n",
            "15.000,00\n",
            "0,00\n",
            "www.xpi.com.br\n",
            "www.xpi.com.br/atendimento\n",
            "Benchmark (CDI)\n",
            "14/07/2021\n",
            "02/08/2021\n",
            "www.xpi.com.br\n",
            "04/10/2021\n",
            "APORTES E RETIRADAS\n",
            "(R$)\n",
            "112.500,00\n",
            "Aug ¹21\n",
            "-100.000,00\n",
            "655.600,00\n",
            "DATA APLICAÇÃO\n",
            "DATA COTA\n",
            "www.xpi.com.br/atendimento\n",
            "30%\n",
            "31/03/2022\n",
            "31/03/2022\n",
            "www.xpi.com.br\n",
            "31/03/2022\n",
            "XP Investimentos CCTVM S/A__\n",
            "Av. Brigadeiro Faria Lima, 3600 110° andar\n",
            "São\n",
            "Paulo | SP\n",
            "CEP 04538-132\n",
            "CNPJ: 02.332.886/0001-04\n",
            "www.xpi.com.br/atendimento\n",
            "DATA COTA\n",
            "Sep ¹21\n",
            "DATA COTA\n",
            "31/03/2022\n",
            "31/03/2022\n",
            "31/03/2022\n",
            "31/03/2022 1,39722880\n",
            "31/03/2022 101,64192375\n",
            "www.xpi.com.br/atendimento\n",
            "0,00\n",
            "0\n",
            "Conta XP\n",
            "Código Assessor de Investimentos\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "Data da posição histórica\n",
            "704,80\n",
            ">www.xpi.com.br\n",
            "IR PAGO\n",
            "(R$)\n",
            "0,00\n",
            "DATA COTA VALOR COTA\n",
            "PATRIMÔNIO FINAL\n",
            "R$ 811.449,86\n",
            "1.055,20\n",
            "1.760,00\n",
            "40%\n",
            "1.562,69\n",
            "VALOR COTA\n",
            "1,51943110\n",
            "1,35336128\n",
            "1,76634100\n",
            "Renda Variável @Renda Fixa\n",
            "13/07/2024\n",
            "01/08/2025\n",
            "03/10/2025\n",
            "0\n",
            "VALOR COTA\n",
            "www.xpi.com.br/atendimento\n",
            "31/03/2022 1,75676790 8093.29136962\n",
            "31/03/2022 1,44157834 16829.5965612\n",
            "31/03/2022 3,00897809 8551.29866777\n",
            "Oct 21\n",
            "VALOR COTA\n",
            "31/03/2022\n",
            "Conta XP\n",
            "Código Assessor de Investimentos\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "Data da posição histórica\n",
            "IPC-A + 5,05%\n",
            "IPC-A +6,15%\n",
            "IPC-A + 5,70%\n",
            "810.878,75\n",
            "DATA VENCIMENTO\n",
            "2,91061840\n",
            "1,32693346 28496.24435172\n",
            "4,15853682 1497.53492722\n",
            "812.634,39\n",
            "6.126,34 794.955,77\n",
            "31/03/2022\n",
            "824.358,34\n",
            "811.449,86\n",
            "4.180,67 780.961,13\n",
            "6.924,55 629.475,49\n",
            "811.449,86\n",
            "QTD. COTAS\n",
            "QTD. GARANTIA QTD. ESTRUTURADOS\n",
            "31/03/2022\n",
            "PATRIMÔNIO FINAL\n",
            "(R$)\n",
            "62631.40083283\n",
            "50%\n",
            "656.421,18\n",
            "19253.16192573\n",
            "58113,23787568\n",
            "Conta XP\n",
            "Código Assessor de Investimentos\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "Data da posição histórica\n",
            "Nov 21\n",
            "400\n",
            "31/03/2022\n",
            "QTD. COTAS\n",
            "QTD. COTAS\n",
            "Conta XP\n",
            "Código Assessor de Investimentos.\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "Data da posição histórica\n",
            "22927.95993361\n",
            "0\n",
            "1162.494505\n",
            "QTD. COTAS\n",
            "Previdência\n",
            "56 0\n",
            "DISPONÍVEL GARANTIA\n",
            "61\n",
            "33\n",
            "Conta XP\n",
            "Código Assessor de Investimentos.\n",
            "Nome Assessor de Investimentos\n",
            "Perfil do Investidor\n",
            "Data da posição histórica\n",
            "31/03/2022\n",
            "Dec ¹21\n",
            "60%\n",
            "DATA COTA VALOR COTA QTD. COTAS EM COTIZAÇÃO POSIÇÃO\n",
            "31/03/2022 2,08431361. 10285.62729024 R$ 0,00\n",
            "31/03/2022 160,78900544 308.04559394 R$ 0,00\n",
            "31/03/2022 143,80153040 105.0231797 R$ 0,00\n",
            "31/03/2022 2,68345360 5549.86872756 R$ 0,00\n",
            "31/03/2022 0,79727610 21730.11571017 R$ 0,00\n",
            "31/03/2022 111,66956310 173.61041682 R$ 0,00\n",
            "1.755,64\n",
            "12.428,75\n",
            "-11.853,28\n",
            "3.254,09\n",
            "APLICADO\n",
            "R$ 56.000,00\n",
            "R$ 33.000,00\n",
            "R$ 61.000,00\n",
            "20.120,98\n",
            "Para informações ligue para 4003-3710 (capitais e regiões metropolitanas) ou 0800-880-3710\n",
            "(demais localidades). Para clientes no exterior o contato é 55-11-4935-2701. Para reclamações,\n",
            "utilize o SAC 0800 77 20202. E se não ficar estiver satisfeito com a solução, favor entrar em\n",
            "contato com a Ouvidoria: 0800 722 3710. Para deficientes auditivos ou de fala favor ligar para\n",
            "0800 771 0101 (todas as localidades).\n",
            "43.166,31\n",
            "79.978,86\n",
            "2.383,87\n",
            "VARIAÇÃO PATRIMONIAL\n",
            "(R$)\n",
            "922,98\n",
            "0\n",
            "0\n",
            "EM COTIZAÇÃO\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "© Fundos\n",
            "_Histórico Posição Consolidada\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "EM COTIZAÇÃO\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "Jan 221\n",
            "EM COTIZAÇÃO\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "0800 771 0101 (todas as localidades).\n",
            "EM COTIZAÇÃO\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "QTD. TOTAL\n",
            "460\n",
            "70%\n",
            "VALOR\n",
            "APLICADO\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "Para informações ligue pars 4003-3710 (capitais e regiões metropolitanas) ou 0800-880-3710\n",
            "(demais localidades). Para clientes no exterior o contato é 55-11-4935-2701. Para reclamações,\n",
            "utilize o SAC 0800 77 20202. E se não ficar estiver satisfeito com a solução, favor entrar em\n",
            "contato com a Ouvidoria: 0800 722 3710. Para deficientes auditivos ou de fala favor ligar para\n",
            "0800 771 0101 (todas as localidades).\n",
            "(%)\n",
            "0,11%\n",
            "0,22%\n",
            "TAXA\n",
            "IPC-A + 5,05%\n",
            "Tesouro Direto\n",
            "1,53%\n",
            "-1,44%\n",
            "0,39%\n",
            "2,57%\n",
            "IPC-A + 5,70%\n",
            "IPC-A +6,15%\n",
            "POSIÇÃO\n",
            "5,47%\n",
            "POSIÇÃO\n",
            "R$ 32.035,61\n",
            "R$ 40.656,77\n",
            "VARIAÇÃO PATRIMONIAL\n",
            "R$ 7.606,21\n",
            "13,94%\n",
            "R$ 95.164,10\n",
            "R$ 26.056,48\n",
            "R$ 102.647,79\n",
            "-0,65%\n",
            "POSIÇÃO\n",
            "POSIÇÃO\n",
            "_Histórico Posição Consolidada\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "R$ 62.913,06\n",
            "R$ 66.367,72\n",
            "R$ 36.859,12\n",
            "Feb '22\n",
            "CONTRATADA\n",
            "R$ 3.383,58\n",
            "R$ 37.812,62\n",
            "R$ 6.227,55\n",
            "Para informações ligue para 4003-3710 (capitais e regiões metropolitanas) ou 0800-880-3710\n",
            "(demais localidades). Para clientes no exterior o contato é 55-11-4935-2701. Para reclamações,\n",
            "utilize o SAC 0800 77 20202. E se não ficar estiver satisfeito com a solução, favor entrar em\n",
            "contato com a Ouvidoria: 0800 722 3710. Para deficientes auditivos ou de fala favor ligar para\n",
            "0800 771 0101 (todas as localidades).\n",
            "POSIÇÃO\n",
            "2365545\n",
            "A67280\n",
            "Pedro Saldanha Scharbert\n",
            "Desatualizado\n",
            "03/2022\n",
            "R$ 95,60\n",
            "RENTABILIDADE BRUTA\n",
            "R$ 14.218,03\n",
            "R$ 24.261,18\n",
            "R$ 25.730,67\n",
            "80%\n",
            "MA COTAÇÃO\n",
            "Mar '22\n",
            "_Histórico Posição Consolidada\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "Para informações ligue pars 4003-3710 (capitais e regiões metropolitanas) ou 0800-880-3710\n",
            "(demais localidades). Para clientes no exterior o contato e 55-11-4935-2701. Para reclamações,\n",
            "utilize o SAC 0800 77 20202. E se não ficar estiver satisfeito com a solução, favor entrar em\n",
            "contato com\n",
            "a Ouvidoria: 0800 722 3710. Para deficientes auditivos ou de fala favor ligar para\n",
            "POSIÇÃO\n",
            "R$ 166.139,90\n",
            "2365545\n",
            "A67280\n",
            "Pedro Saldanha Scharbert\n",
            "Desatualizado\n",
            "03/2022\n",
            "20,00%\n",
            "VALOR\n",
            "LÍQUIDO\n",
            "VALOR LÍQUIDO\n",
            "VALOR LÍQUIDO\n",
            "R$ 21.438,47 R$ 21.221,90\n",
            "R$ 49.530,34 R$ 49.530,34\n",
            "R$ 15.102,49 R$ 15.102,49\n",
            "R$ 14.892,82 R$ 14.892,82\n",
            "R$ 17.324,90 R$ 17.324,90\n",
            "R$ 19.387,00 R$ 19.387,00\n",
            "20,00%\n",
            "20,00%\n",
            "TOTAL\n",
            "R$ 61.530,45\n",
            "R$ 65.159,98\n",
            "R$ 36.087,30\n",
            "R$ 94.261,74\n",
            "R$ 25.752,31\n",
            "R$ 101.650,95\n",
            "_Histórico Posição Consolidada\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "POSIÇÃO\n",
            "R$ 545.870,40\n",
            "VALOR LÍQUIDO\n",
            "VALOR LÍQUIDO\n",
            "R$ 31.859,37\n",
            "R$ 40.509,00\n",
            "R$ 3.383,58\n",
            "R$ 36.640,73\n",
            "R$ 6.043,42\n",
            "CDI)\n",
            "VALOR LÍQUIDO\n",
            "R$ 13.585,33\n",
            "R$ 24.225,00\n",
            "R$ 25.730,67\n",
            "14,81%\n",
            "28,88%\n",
            "TAXA IR\n",
            "2365545\n",
            "A67280\n",
            "Pedro Saldanha Scharbert\n",
            "Desatualizado\n",
            "03/2022\n",
            "VALOR\n",
            "R$ 68 372,04\n",
            "_Histórico Posição Consolidada\n",
            "Data da Consulta: 02/05/2022 22:14\n",
            "OSIÇÃO\n",
            "R$ 43.976,00\n",
            "58,54%\n",
            "R$ 40.632,86\n",
            "R$ 0,00\n",
            "R$ 27.739,18\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 0,00\n",
            "R$ 40.632,86\n",
            "Movimentações\n",
            "165,60%\n",
            "-192,83%\n",
            "12,35%\n",
            "POSIÇÃO\n",
            "R$ 43.976,00\n",
            "VALDR\n",
            "R$ 824.358,34\n",
            "2365545\n",
            "A67280\n",
            "Pedro Saldanha Scharbert\n",
            "Desatualizado\n",
            "03/2022\n",
            "197,60%\n",
            "-12,20%\n",
            "90%\n",
            "233,58%\n",
            "RENTABILIDADE BRUTA (%\n",
            "2365545\n",
            "A67280\n",
            "Pedro Saldanha Scharbert\n",
            "Desatualizado\n",
            "03/2022\n",
            "Apr ¹22\n",
            "Highcharts.com\n",
            "100%\n",
            "LÍQUIDO\n",
            "R$ 62.433,15\n",
            "R$ 36.677,58\n",
            "R$ 66.414,18\n",
            "R$ 165.524,91\n",
            "para 4003-3710 (capitais e regiões metropolitanas) ou 0800-880-3710\n",
            "Para\n",
            "no exterior o contato é 55-11-4935-2701. Para reclamações,\n",
            "Para informações ligue\n",
            "(demais localidades).\n",
            "clientes\n",
            "utilize o SAC 0800 77 20202. E se não ficar estiver satisfeito com a solução, favor entrar em\n",
            "contato com\n",
            "a Ouvidoria:\n",
            "0800\n",
            "722\n",
            "3710.\n",
            "Para\n",
            "deficientes\n",
            "auditivos ou de fala\n",
            "favor\n",
            "ligar para\n",
            "0800 771 0101 (todas as localidades).\n"
          ]
        }
      ],
      "source": [
        "text_detection_params = vision_v1.types.TextDetectionParams(\n",
        "    enable_text_detection_confidence_score=True,\n",
        "    advanced_ocr_options=['msa'],\n",
        ")\n",
        "\n",
        "image_context = vision_v1.types.ImageContext(\n",
        "    language_hints=['pt'], \n",
        "    text_detection_params=text_detection_params\n",
        ")\n",
        "\n",
        "# Faça uma solicitação para ler o texto da imagem\n",
        "response = client.annotate_image({\"image\": image, \"image_context\": image_context})\n",
        "\n",
        "response = client.text_detection(image=image)\n",
        "text_annotations = response.text_annotations\n",
        "\n",
        "# Imprima o texto da imagem\n",
        "print(text_annotations[0].description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XptKoS72bFJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JU9t12Ttxob"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-DRb66puF3wV"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}