{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HpDiniz/Leitor-de-PDF/blob/main/PDF_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install tabula-py\n",
        "!pip install pdfminer\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN56rH8TrYQy",
        "outputId": "b1022108-4aa9-4d2b-c160-1501038a1160"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.8/dist-packages (0.3.10)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.8/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tabula-py in /usr/local/lib/python3.8/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tabula-py) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.8/dist-packages (from tabula-py) (1.3.5)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.8/dist-packages (from tabula-py) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.25.3->tabula-py) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->tabula-py) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfminer in /usr/local/lib/python3.8/dist-packages (20191125)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.8/dist-packages (from pdfminer) (3.17)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.8/dist-packages (3.0.1)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import tabula\n",
        "import PyPDF2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from io import StringIO\n",
        "from google.colab import files\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter"
      ],
      "metadata": {
        "id": "QAdgDBRi1FXU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_objects = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CFpNjOojq_j7",
        "outputId": "08744481-e9b5-4b95-ff52-b0e823c18893"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bbfab698-fd27-45c6-b6db-f4f004a40bbc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bbfab698-fd27-45c6-b6db-f4f004a40bbc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving - Posicao Consolidada XP - 55432.pdf to - Posicao Consolidada XP - 55432 (4).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte o conteúdo do PDF para texto\n",
        "def convert_pdf_to_txt(path):\n",
        "\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    retstr = StringIO()\n",
        "    laparams = LAParams()\n",
        "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "    fp = open(path, 'rb')\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    password = \"\"\n",
        "    maxpages = 0\n",
        "    caching = True\n",
        "    pagenos=set()\n",
        "\n",
        "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
        "        interpreter.process_page(page)\n",
        "\n",
        "    text = retstr.getvalue()\n",
        "\n",
        "    fp.close()\n",
        "    device.close()\n",
        "    retstr.close()\n",
        "\n",
        "    return text\n",
        "\n",
        "def get_content_of_tables(pdf_file):\n",
        "    # Extrair todas as tabelas do arquivo PDF\n",
        "    tables = tabula.read_pdf(pdf_file, multiple_tables=True, pages=\"all\")\n",
        "\n",
        "    return tables\n",
        "\n",
        "def get_text_from_page_images(reader):\n",
        "\n",
        "    # Inicializa variáveis\n",
        "    texts = []\n",
        "    page_number = 0\n",
        "\n",
        "    # Percore todas as páginas do documento\n",
        "    for page in reader.pages:\n",
        "        \n",
        "        page_number += 1\n",
        "\n",
        "        try:\n",
        "            # Obtém os recursos da página\n",
        "            xObject = page['/Resources']['/XObject'].get_object()\n",
        "\n",
        "            image_number = 0\n",
        "            # Percorre todos os objetos X da página\n",
        "            for obj in xObject:\n",
        "\n",
        "                image_number += 1\n",
        "\n",
        "                # Verifica se o objeto é uma imagem\n",
        "                if xObject[obj]['/Subtype'] == '/Image':\n",
        "                    size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
        "                    data = xObject[obj].get_data()\n",
        "                    if xObject[obj]['/ColorSpace'] == '/DeviceRGB':\n",
        "                        mode = \"RGB\"\n",
        "                    else:\n",
        "                        mode = \"P\"\n",
        "\n",
        "                    # Cria uma imagem a partir dos dados\n",
        "                    img = Image.frombytes(mode, size, data)\n",
        "                    image_name = file_name[0:25] + \"_\" + str(page_number) + \"_\" + str(image_number) + \".png\"\n",
        "                    #image_path = pdf_path = \"/content/gdrive/My Drive/Temp/\" + image_name\n",
        "\n",
        "                    # Salva a imagem\n",
        "                    img.save(image_name)\n",
        "\n",
        "                    # Carrega a imagem\n",
        "                    image = cv2.imread(image_name)\n",
        "\n",
        "                    # Converte a imagem para escala de cinza\n",
        "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                    # Executa o OCR usando o Tesseract\n",
        "                    text = pytesseract.image_to_string(image).strip()\n",
        "\n",
        "                    # Adiciona o texto obtido ao array de textos\n",
        "                    texts.append(text)\n",
        "        except:\n",
        "            texts.append(f'Não foi possível ler as imagens da página {page_number}')\n",
        "    \n",
        "    return texts\n",
        "\n",
        "def create_new_df():\n",
        "\n",
        "    # Cria um DataFrame utilizado no consolidado final\n",
        "    return pd.DataFrame({\n",
        "        'CLASSIFICAÇÃO': pd.Series(dtype='str'),\n",
        "        'ATIVO': pd.Series(dtype='str'),\n",
        "        'EXPOSIÇÃO': pd.Series(dtype='str'),\n",
        "        'INSTITUIÇÃO': pd.Series(dtype='str'),\n",
        "        'ATUAL': pd.Series(dtype='float64'),\n",
        "        'DATA': pd.Series(dtype='str'),\n",
        "        'ON/OFF': pd.Series(dtype='str'),\n",
        "        'DATA DE VENCIMENTO': pd.Series(dtype='str'),\n",
        "        'INDEXADOR': pd.Series(dtype='str')\n",
        "    })\n",
        "\n",
        "def get_tipo_extrato(text_pypdf, text_pdfminer):\n",
        "\n",
        "    text_1 = text_pypdf[0:100].lower().replace(\" \",\"\").replace(\"\\n\",\"\")\n",
        "    text_2 = text_pdfminer[0:100].lower().replace(\" \",\"\").replace(\"\\n\",\"\")\n",
        "\n",
        "    if 'extratodecotista' in text_1 and 'extratodecotista' in text_2:\n",
        "        return \"Extrato de Cotista XP\"\n",
        "    elif 'posição&performance' in text_1 and 'posição&performance' in text_2:\n",
        "        return \"Posição e Performance XP\"\n",
        "\n",
        "    return \"Posição Consolidada XP\"\n",
        "\n",
        "def obtem_classificacao(ativo):\n",
        "\n",
        "    # Verifica se é uma ativo no formato de Ticker\n",
        "    founded = re.search(r'\\b[A-Z]{4}(3|4|5|6|11|32|33|34|35)\\b', ativo, flags=(re.IGNORECASE))\n",
        "    if founded:\n",
        "        return \"Ações\"\n",
        "    \n",
        "    # Define as palavras chave para cada Classificação\n",
        "    dict_classificacoes = {\n",
        "        \"Ações\": [\n",
        "            \"FIC FIA\",\"FIA\",\"FI Ações\", \"FI Açoes\"\n",
        "        ],\n",
        "        \"Renda Fixa\": [\n",
        "            \"Renda Fixa\",\"RF\",\"CDB\",\"LC\",\"LF\",\"LFSN\",\"LFSC\",\"LCA\",\"LCI\",\"CRA\",\"CRI\",\"Deb\",\n",
        "            \"Debenture\",\"Debênture\",\"Tesouro\",\"Pré\",\"Pós\",\"Pre\",\"Pos\",\"IPCA\",\"IPCA+\",\"LTN\",\n",
        "            \"NTN\",\"NTN-B\",\"NTNB\",\"DI\",\"REF DI\",\"CP\",\"Credito Privado\",\"Crédito Privado\",\n",
        "            \"LP\",\"Longo Prazo\",\"Previdencia\",\"Previdência\",\"Prev\",\"VGBL\",\"PGBL\"\n",
        "        ],\n",
        "        \"Multimercado\": [\n",
        "            \"FIC FIM\",\"FIM\",\"MM\",\"Multimercado\",\"Multi\",\"COE\",\"Multiestratégia\",\n",
        "            \"Multiestratégia\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    classes = []\n",
        "    # Percorre cada uma das classificações\n",
        "    for classificacao in dict_classificacoes:\n",
        "\n",
        "        # Percorre as palavras-chave de cada uma das classificações\n",
        "        for key in dict_classificacoes[classificacao]:\n",
        "\n",
        "            # Verifica se a palavra-chave atual existe no nome do ativo\n",
        "            founded = re.search(r'\\b' + key + r'\\b', ativo, flags=(re.IGNORECASE))\n",
        "            if founded and not classificacao in classes:\n",
        "                classes.append(classificacao)\n",
        "\n",
        "    if len(classes) > 0:\n",
        "        return ' / '.join(classes)\n",
        "\n",
        "    # Se nenhuma classificação foi encontrada, verifica se é um ETF de investimento estrangeiro\n",
        "    founded = re.search(r'\\b[A-Z]{3}\\b', ativo, flags=(re.IGNORECASE))\n",
        "    if founded:\n",
        "        return \"Ações\"\n",
        "\n",
        "    return \"***\"\n",
        "\n",
        "def get_pdf_texts(file):\n",
        "\n",
        "    text_pypdf = \"\"\n",
        "    text_pdfminer = \"\"\n",
        "\n",
        "    file_name, file_extension = os.path.splitext(file)\n",
        "\n",
        "    if file_extension != '.pdf':\n",
        "        return text_pypdf, text_pdfminer\n",
        "\n",
        "    # Lê o conteúdo do arquivo PDF\n",
        "    text_pdfminer = convert_pdf_to_txt(file)\n",
        "    \n",
        "    reader = PyPDF2.PdfReader(file)\n",
        "    page_number = 0\n",
        "\n",
        "    for page in reader.pages:\n",
        "\n",
        "        page_number += 1\n",
        "        text_pypdf = text_pypdf + page.extract_text() #visitor_text=remove_header_and_footer)\n",
        "    \n",
        "    # print(get_text_from_page_images(reader))\n",
        "\n",
        "    return text_pypdf, text_pdfminer\n",
        "\n",
        "def write_consolidado(df, regex_result, data_emissao, classification = None):\n",
        "    \n",
        "    # Preenche o consolidado final\n",
        "    for res in regex_result:\n",
        "\n",
        "        # Faça atribuições\n",
        "        ativo = res[0].replace('\\n', ' ').strip()\n",
        "        data_vencimento = res[1].replace('\\n', ' ').strip()\n",
        "        indexador = res[2].replace('\\n', ' ').strip() #.replace('.','')\n",
        "        valor_bruto = res[3].replace('\\n', ' ').strip() #.replace('.','')\n",
        "        classificacao = classification if classification != None else obtem_classificacao(ativo)\n",
        "        \n",
        "        # Se for encontrada alguma data no nome do ativo, algum registro inválido foi coletado\n",
        "        if re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', ativo):\n",
        "            continue\n",
        "\n",
        "        # Caso a data de vencimento encontrada, não seja uma data, altere seu valor para \"-\"\n",
        "        if not re.search(r'\\d{2}\\/\\d{2}\\/\\d{4}', data_vencimento):\n",
        "            data_vencimento = \"-\"\n",
        "\n",
        "        # Adiciona os novos valores ao DataFrame\n",
        "        df = df.append({\n",
        "            'CLASSIFICAÇÃO': classificacao,\n",
        "            'ATIVO': ativo,\n",
        "            'EXPOSIÇÃO': \"Real\",\n",
        "            'INSTITUIÇÃO': \"XP Investimentos\",\n",
        "            'ATUAL': valor_bruto,\n",
        "            'DATA': data_emissao,\n",
        "            'ON/OFF': \"ON\",\n",
        "            'DATA DE VENCIMENTO': data_vencimento,\n",
        "            'INDEXADOR': \"-\"\n",
        "        }, ignore_index=True)\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "luw85ugomDsZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtem_posicao_performance_xp(text_pypdf):\n",
        "\n",
        "    # Cria o dataFrame resultante\n",
        "    df_result = create_new_df()\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    regex = r'\\n[\\d\\/]*([a-zA-Z].+?\\s*-\\s*[A-Z]{3}\\/\\d{4})\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4}|\\-)\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s]+)[\\d.]+,\\d\\d\\s*[\\d.]+,\\d\\d'\n",
        "    result = re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    for res in result:\n",
        "        print(res)\n",
        "\n",
        "    return df_result\n",
        "\n",
        "def obtem_posicao_consolidada_xp(text_pypdf):\n",
        "\n",
        "    # Cria o dataFrame resultante\n",
        "    df_result = create_new_df()\n",
        "\n",
        "    # Regex para obter a Data de Emissão\n",
        "    regex = \"(?<=Data da Consulta: )\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = re.search(regex, text_pypdf, flags=(re.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa\n",
        "    regex = r'\\n[\\d\\/]*([a-zA-Z].+?\\s*-\\s*[A-Z]{3}\\/\\d{4})\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s])*\\d+\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}'\n",
        "    result = re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa sem carência\n",
        "    regex = r'\\n[\\d\\/]*([a-zA-Z].+?\\s*-\\s*[A-Z]{3}\\/\\d{4})\\s*\\d{2}\\/\\d{2}\\/\\d{4}\\s*\\-\\s*(\\d{2}\\/\\d{2}\\/\\d{4})\\s*([A-Z\\-\\+\\s]*\\s*[\\d,.]+%[A-Z\\-\\s])+\\d+\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}'\n",
        "    result = result + re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    for res in result:\n",
        "        print(res)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem ativos de Renda Fixa Pós-Fixados\n",
        "    regex = r'\\n[\\d\\/]*([a-zA-Z].+?)\\s*\\d{2}\\/\\d{2}\\/(\\d{4})\\s*[\\d,.]+\\s*[\\d,.]+\\s*R\\$\\s*[\\d,.]+\\s*R\\$\\s*([\\d,.]+)\\s*R\\$\\s*[\\d,.]+'\n",
        "    result = result + re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem Fundos Imobiliários\n",
        "    regex = r'([A-Z]{4}(3|4|5|6|11|32|33|34|35))\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    result = result + re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem COEs\n",
        "    regex = r'\\n[\\d\\/]*([a-zA-Z].+?)\\s*-\\s*[\\w\\s,.]*\\s*-\\s*\\s*\\d{2}\\.\\d{2}\\.\\d{4}\\s*[\\w\\s,.]*\\d{2}\\/\\d{2}\\/\\d{4}\\s+(\\d{2}\\/\\d{2}\\/\\d{4})\\s+\\d+\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    result_coes = re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem Ações\n",
        "    regex = r'([A-Z]{4}(3|4|5|6|11|32|33|34|35))\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+\\d+\\s+R\\$\\s*[\\d,.]+[.,]\\d{2}\\s*R\\$\\s*([\\d,.]+[.,]\\d{2})'\n",
        "    result_acoes = re.findall(regex, text_pypdf, flags=(re.IGNORECASE | re.MULTILINE))\n",
        "\n",
        "    df_result = write_consolidado(df_result, result, data_emissao)\n",
        "    df_result = write_consolidado(df_result, result_coes, data_emissao, \"Multimercado\")\n",
        "    df_result = write_consolidado(df_result, result_acoes, data_emissao)\n",
        "\n",
        "    return df_result\n",
        "\n",
        "def obtem_extrato_cotista_xp(text_pypdf, text_pdfminer):\n",
        "\n",
        "    # Cria o dataFrame resultante\n",
        "    df_result = create_new_df()\n",
        "\n",
        "    # Regex para obter a data de emissão\n",
        "    regex_0 = \"(?<=Movimenta..o de \\d{2}\\/\\d{2}\\/\\d{4} a )\\d{2}\\/\\d{2}\\/\\d{4}\"\n",
        "    data_emissao = re.search(regex_0, text_pdfminer, flags=(re.IGNORECASE)).group(0)\n",
        "\n",
        "    # Regex para obter o texto situado entre o termo \"POSIÇÃO CONSOLIDADA\" e o termo \"Emissão\"\n",
        "    regex_1 = \"(?<=POSI..O CONSOLIDADA).*?(?=Emissão:)\"\n",
        "    result_1 = re.search(regex_1, text_pdfminer, flags=(re.IGNORECASE | re.DOTALL)).group(0)\n",
        "\n",
        "    # Regex para obter todas as linhas que possuírem pelo menos uma letra e um espaço\n",
        "    regex_2 = \"^.*[a-zA-Z] .*$\"\n",
        "    result_2 = re.finditer(regex_2, result_1, flags=(re.MULTILINE))\n",
        "\n",
        "    # Regex para obter o texto situado entre o termo \"POSIÇÃOCONSOLIDADA\" e o termo \"TotalnaInstituição\"\n",
        "    regex_3 = \"(?<=POSI..OCONSOLIDADA\\n).*?(?=TotalnaInstituição)\"\n",
        "    result_3 = re.search(regex_3, text_pypdf, flags=(re.IGNORECASE | re.DOTALL)).group(0)\n",
        "\n",
        "    # Substitui os espaços por um ponto e vírgula, para simular uma tabela CSV\n",
        "    result_3 = result_3.replace(\" \",\";\")\n",
        "\n",
        "    # Corrige termos com espaço\n",
        "    for result in result_2:\n",
        "        value = result.group(0)\n",
        "        key = value.replace(\" \",\"\")\n",
        "        result_3 = result_3.replace(key,value)\n",
        "\n",
        "    # Converte o CSV para o tipo DataFrame\n",
        "    df = pd.read_csv(StringIO(result_3), sep=\";\")\n",
        "    \n",
        "    # Cria um array de tuplas\n",
        "    result = []\n",
        "\n",
        "    # Preenche o consolidado final\n",
        "    for index, row in df.iterrows():\n",
        "        result.append((row['Fundo'],\"-\",row[\"Valor Bruto\"]))\n",
        "\n",
        "    df_result = write_consolidado(df_result, result, data_emissao)\n",
        "\n",
        "    return df_result"
      ],
      "metadata": {
        "id": "y3qx17PMRHgj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorre cada um dos arquivos\n",
        "for file in file_objects.keys():\n",
        "\n",
        "    df_result = create_new_df()\n",
        "    text_pypdf, text_pdfminer = get_pdf_texts(file)\n",
        "    tipo_extrato = get_tipo_extrato(text_pypdf, text_pdfminer)\n",
        "\n",
        "    if tipo_extrato == \"Extrato de Cotista XP\":\n",
        "        df_result = obtem_extrato_cotista_xp(text_pypdf, text_pdfminer)\n",
        "    elif tipo_extrato == \"Posição Consolidada XP\":\n",
        "        df_result = obtem_posicao_consolidada_xp(text_pypdf)\n",
        "    elif tipo_extrato == \"Posição e Performance XP\":\n",
        "        df_result = obtem_posicao_performance_xp(text_pypdf)\n",
        "\n",
        "    file_name, file_extension = os.path.splitext(file)\n",
        "\n",
        "    # df_result.to_excel(file_name + \".xlsx\", index=False) \n",
        "    # files.download(file_name + \".xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O198Ldn5niOA",
        "outputId": "7665c5e7-d88a-4ec6-8bc1-76e1cf3cac3e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('CDB PINE - NOV/2024', '08/11/2024', '+ 13,05%\\n', '112.744,61')\n",
            "('CDB ORIGINAL - JUN/2025', '21/06/2025', '+ 10,60%\\n', '245.774,44')\n",
            "('NTN-B \\n- MAI/2055', '15/05/2055', 'IPC-A + 4,46%\\n', '40.569,67')\n",
            "('NTN-B \\n- AGO/2030', '15/08/2030', 'IPC-A + 4,53%\\n', '100.212,81')\n",
            "('NTN-B \\n- MAI/2035', '15/05/2035', 'IPC-A + 4,35%\\n', '83.870,32')\n",
            "('NTN-B \\n- AGO/2028', '15/08/2028', 'IPC-A + 4,29%\\n', '86.440,48')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbnGlA9CPHxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}